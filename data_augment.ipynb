{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Audio\n",
    "from utils.utils import utils\n",
    "utils = utils()\n",
    "\n",
    "# Get the data from https://www.kaggle.com/kongaevans/speaker-recognition-dataset/download\n",
    "DATASET_ROOT = \"./16000_pcm_speeches\"\n",
    "\n",
    "# The folders in which we will put the audio samples and the noise samples\n",
    "AUDIO_SUBFOLDER = \"audio\"\n",
    "NOISE_SUBFOLDER = \"noise\"\n",
    "DATASET_AUDIO_PATH = os.path.join(DATASET_ROOT, AUDIO_SUBFOLDER)\n",
    "DATASET_NOISE_PATH = os.path.join(DATASET_ROOT, NOISE_SUBFOLDER)\n",
    "\n",
    "VALID_SPLIT = 0.1 # Percentage of samples to use for validation\n",
    "SHUFFLE_SEED = 43 # Seed to use when shuffling the dataset and the noise\n",
    "\n",
    "# The sampling rate toresample at. Also the output size of audio files (1 second)\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# The factor to multiply the noise with according to:\n",
    "#   noisy_sample = sample + noise * prop * scale\n",
    "#      where prop = sample_amplitude / noise_amplitude\n",
    "SCALE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If folder `audio`, does not exist, create it, otherwise do nothing\n",
    "if os.path.exists(DATASET_AUDIO_PATH) is False:\n",
    "    os.makedirs(DATASET_AUDIO_PATH)\n",
    "\n",
    "# If folder `noise`, does not exist, create it, otherwise do nothing\n",
    "if os.path.exists(DATASET_NOISE_PATH) is False:\n",
    "    os.makedirs(DATASET_NOISE_PATH)\n",
    "\n",
    "for folder in os.listdir(DATASET_ROOT):\n",
    "    if os.path.isdir(os.path.join(DATASET_ROOT, folder)):\n",
    "        if folder in [AUDIO_SUBFOLDER, NOISE_SUBFOLDER]:\n",
    "            # If folder is `audio` or `noise`, do nothing\n",
    "            continue\n",
    "        elif folder in [\"other\", \"_background_noise_\"]:\n",
    "            # If folder is one of the folders that contains noise samples,\n",
    "            # move it to the `noise` folder\n",
    "            shutil.move(\n",
    "                os.path.join(DATASET_ROOT, folder),\n",
    "                os.path.join(DATASET_NOISE_PATH, folder),\n",
    "            )\n",
    "        else:\n",
    "            # Otherwise, it should be a speaker folder, then move it to\n",
    "            # `audio` folder\n",
    "            shutil.move(\n",
    "                os.path.join(DATASET_ROOT, folder),\n",
    "                os.path.join(DATASET_AUDIO_PATH, folder),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 files belonging to 2 directories\n",
      "61 slices, [<tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       ...,\n",
      "       [-0.00695801],\n",
      "       [ 0.00799561],\n",
      "       [ 0.0350647 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02267456],\n",
      "       [ 0.02301025],\n",
      "       [ 0.03671265],\n",
      "       ...,\n",
      "       [ 0.04626465],\n",
      "       [ 0.01608276],\n",
      "       [-0.00585938]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.0272522 ],\n",
      "       [ 0.00085449],\n",
      "       [-0.02471924],\n",
      "       ...,\n",
      "       [ 0.0274353 ],\n",
      "       [ 0.00796509],\n",
      "       [ 0.02160645]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01400757],\n",
      "       [ 0.03594971],\n",
      "       [ 0.04772949],\n",
      "       ...,\n",
      "       [ 0.01580811],\n",
      "       [-0.02340698],\n",
      "       [-0.00744629]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.0241394 ],\n",
      "       [ 0.00119019],\n",
      "       [-0.00201416],\n",
      "       ...,\n",
      "       [ 0.02359009],\n",
      "       [ 0.00714111],\n",
      "       [-0.02166748]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00445557],\n",
      "       [-0.00769043],\n",
      "       [-0.02420044],\n",
      "       ...,\n",
      "       [-0.01776123],\n",
      "       [ 0.01025391],\n",
      "       [ 0.00616455]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02020264],\n",
      "       [ 0.00891113],\n",
      "       [-0.00357056],\n",
      "       ...,\n",
      "       [-0.01852417],\n",
      "       [-0.02243042],\n",
      "       [ 0.00924683]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00842285],\n",
      "       [-0.00445557],\n",
      "       [ 0.0017395 ],\n",
      "       ...,\n",
      "       [ 0.05099487],\n",
      "       [ 0.01623535],\n",
      "       [ 0.00695801]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00363159],\n",
      "       [ 0.01464844],\n",
      "       [ 0.02423096],\n",
      "       ...,\n",
      "       [-0.03762817],\n",
      "       [ 0.03305054],\n",
      "       [ 0.06134033]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02481079],\n",
      "       [-0.00866699],\n",
      "       [-0.00891113],\n",
      "       ...,\n",
      "       [ 0.02713013],\n",
      "       [ 0.01205444],\n",
      "       [ 0.02246094]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00473022],\n",
      "       [-0.00662231],\n",
      "       [-0.01034546],\n",
      "       ...,\n",
      "       [-0.00695801],\n",
      "       [ 0.00442505],\n",
      "       [ 0.01821899]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.03530884],\n",
      "       [-0.02243042],\n",
      "       [-0.02523804],\n",
      "       ...,\n",
      "       [-0.01486206],\n",
      "       [ 0.01687622],\n",
      "       [-0.01419067]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00390625],\n",
      "       [-0.02130127],\n",
      "       [-0.02023315],\n",
      "       ...,\n",
      "       [ 0.01116943],\n",
      "       [ 0.00482178],\n",
      "       [-0.01156616]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00848389],\n",
      "       [ 0.02770996],\n",
      "       [ 0.00280762],\n",
      "       ...,\n",
      "       [-0.00671387],\n",
      "       [-0.01159668],\n",
      "       [-0.02914429]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01135254],\n",
      "       [-0.03018188],\n",
      "       [-0.00082397],\n",
      "       ...,\n",
      "       [ 0.        ],\n",
      "       [-0.01690674],\n",
      "       [-0.03417969]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.0161438 ],\n",
      "       [ 0.00402832],\n",
      "       [-0.00802612],\n",
      "       ...,\n",
      "       [ 0.07440186],\n",
      "       [-0.01101685],\n",
      "       [-0.00460815]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00112915],\n",
      "       [-0.009552  ],\n",
      "       [ 0.00814819],\n",
      "       ...,\n",
      "       [-0.02749634],\n",
      "       [-0.01068115],\n",
      "       [-0.00494385]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01895142],\n",
      "       [-0.02545166],\n",
      "       [ 0.01898193],\n",
      "       ...,\n",
      "       [-0.00216675],\n",
      "       [-0.00811768],\n",
      "       [-0.02206421]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00466919],\n",
      "       [-0.03305054],\n",
      "       [-0.00543213],\n",
      "       ...,\n",
      "       [-0.00930786],\n",
      "       [-0.01177979],\n",
      "       [-0.01461792]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02639771],\n",
      "       [ 0.02209473],\n",
      "       [-0.00143433],\n",
      "       ...,\n",
      "       [ 0.00360107],\n",
      "       [-0.02444458],\n",
      "       [-0.04290771]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02404785],\n",
      "       [-0.03198242],\n",
      "       [ 0.01190186],\n",
      "       ...,\n",
      "       [ 0.03735352],\n",
      "       [-0.00158691],\n",
      "       [ 0.03338623]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00473022],\n",
      "       [-0.03500366],\n",
      "       [-0.01275635],\n",
      "       ...,\n",
      "       [-0.03289795],\n",
      "       [-0.02212524],\n",
      "       [-0.01919556]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00283813],\n",
      "       [-0.00460815],\n",
      "       [-0.00588989],\n",
      "       ...,\n",
      "       [-0.00421143],\n",
      "       [-0.03710938],\n",
      "       [-0.02471924]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02987671],\n",
      "       [ 0.00244141],\n",
      "       [ 0.01010132],\n",
      "       ...,\n",
      "       [-0.01165771],\n",
      "       [-0.01843262],\n",
      "       [-0.01925659]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02368164],\n",
      "       [-0.0039978 ],\n",
      "       [-0.00067139],\n",
      "       ...,\n",
      "       [-0.00326538],\n",
      "       [-0.01553345],\n",
      "       [-0.01577759]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00213623],\n",
      "       [-0.02334595],\n",
      "       [-0.0112915 ],\n",
      "       ...,\n",
      "       [ 0.01370239],\n",
      "       [-0.03643799],\n",
      "       [-0.02911377]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00390625],\n",
      "       [ 0.00875854],\n",
      "       [-0.00814819],\n",
      "       ...,\n",
      "       [-0.00466919],\n",
      "       [ 0.01089478],\n",
      "       [-0.01690674]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00595093],\n",
      "       [ 0.00079346],\n",
      "       [-0.02053833],\n",
      "       ...,\n",
      "       [ 0.02017212],\n",
      "       [ 0.01104736],\n",
      "       [-0.0090332 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01229858],\n",
      "       [-0.00808716],\n",
      "       [-0.01541138],\n",
      "       ...,\n",
      "       [-0.01135254],\n",
      "       [-0.0145874 ],\n",
      "       [ 0.01647949]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01245117],\n",
      "       [-0.01538086],\n",
      "       [ 0.02178955],\n",
      "       ...,\n",
      "       [ 0.00823975],\n",
      "       [-0.02441406],\n",
      "       [-0.01382446]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.0350647 ],\n",
      "       [-0.00790405],\n",
      "       [-0.00765991],\n",
      "       ...,\n",
      "       [-0.00915527],\n",
      "       [-0.0015564 ],\n",
      "       [ 0.01681519]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.04382324],\n",
      "       [-0.01358032],\n",
      "       [ 0.02069092],\n",
      "       ...,\n",
      "       [-0.00146484],\n",
      "       [ 0.00326538],\n",
      "       [ 0.0201416 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00057983],\n",
      "       [-0.02548218],\n",
      "       [-0.00479126],\n",
      "       ...,\n",
      "       [ 0.01443481],\n",
      "       [ 0.0199585 ],\n",
      "       [ 0.01745605]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01715088],\n",
      "       [ 0.01748657],\n",
      "       [ 0.0116272 ],\n",
      "       ...,\n",
      "       [-0.02209473],\n",
      "       [-0.0274353 ],\n",
      "       [-0.00775146]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01312256],\n",
      "       [ 0.01748657],\n",
      "       [ 0.00473022],\n",
      "       ...,\n",
      "       [ 0.00756836],\n",
      "       [-0.00964355],\n",
      "       [ 0.01400757]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02175903],\n",
      "       [ 0.01556396],\n",
      "       [ 0.02490234],\n",
      "       ...,\n",
      "       [ 0.01159668],\n",
      "       [ 0.01260376],\n",
      "       [-0.01901245]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01086426],\n",
      "       [-0.02307129],\n",
      "       [-0.01455688],\n",
      "       ...,\n",
      "       [-0.02191162],\n",
      "       [ 0.01300049],\n",
      "       [ 0.02218628]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01947021],\n",
      "       [-0.04022217],\n",
      "       [ 0.02896118],\n",
      "       ...,\n",
      "       [ 0.01217651],\n",
      "       [-0.00897217],\n",
      "       [-0.01599121]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02511597],\n",
      "       [-0.00631714],\n",
      "       [-0.02047729],\n",
      "       ...,\n",
      "       [ 0.00570679],\n",
      "       [ 0.02774048],\n",
      "       [ 0.01135254]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00665283],\n",
      "       [ 0.00045776],\n",
      "       [ 0.01275635],\n",
      "       ...,\n",
      "       [-0.0027771 ],\n",
      "       [-0.00839233],\n",
      "       [-0.00595093]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01541138],\n",
      "       [ 0.0020752 ],\n",
      "       [-0.02102661],\n",
      "       ...,\n",
      "       [ 0.02108765],\n",
      "       [-0.02435303],\n",
      "       [-0.00109863]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02703857],\n",
      "       [-0.03118896],\n",
      "       [ 0.03991699],\n",
      "       ...,\n",
      "       [ 0.02908325],\n",
      "       [-0.00323486],\n",
      "       [ 0.02651978]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.04064941],\n",
      "       [ 0.0239563 ],\n",
      "       [ 0.01452637],\n",
      "       ...,\n",
      "       [-0.00274658],\n",
      "       [ 0.03417969],\n",
      "       [ 0.02355957]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.02474976],\n",
      "       [0.03204346],\n",
      "       [0.00357056],\n",
      "       ...,\n",
      "       [0.02816772],\n",
      "       [0.01638794],\n",
      "       [0.0635376 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02163696],\n",
      "       [ 0.02127075],\n",
      "       [-0.03753662],\n",
      "       ...,\n",
      "       [-0.00183105],\n",
      "       [-0.03286743],\n",
      "       [-0.00469971]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02359009],\n",
      "       [-0.0088501 ],\n",
      "       [-0.00814819],\n",
      "       ...,\n",
      "       [ 0.03161621],\n",
      "       [ 0.05273438],\n",
      "       [ 0.0397644 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02349854],\n",
      "       [-0.00140381],\n",
      "       [-0.03152466],\n",
      "       ...,\n",
      "       [-0.01119995],\n",
      "       [-0.01998901],\n",
      "       [ 0.03256226]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02536011],\n",
      "       [-0.00952148],\n",
      "       [ 0.01013184],\n",
      "       ...,\n",
      "       [-0.00894165],\n",
      "       [ 0.0039978 ],\n",
      "       [-0.00601196]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00888062],\n",
      "       [-0.00024414],\n",
      "       [-0.00393677],\n",
      "       ...,\n",
      "       [-0.03121948],\n",
      "       [ 0.01721191],\n",
      "       [ 0.00378418]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01882935],\n",
      "       [ 0.00927734],\n",
      "       [ 0.02828979],\n",
      "       ...,\n",
      "       [-0.01828003],\n",
      "       [ 0.00750732],\n",
      "       [ 0.01266479]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.015625  ],\n",
      "       [-0.00036621],\n",
      "       [-0.01098633],\n",
      "       ...,\n",
      "       [ 0.00280762],\n",
      "       [-0.00546265],\n",
      "       [ 0.00473022]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00115967],\n",
      "       [-0.01419067],\n",
      "       [-0.01589966],\n",
      "       ...,\n",
      "       [ 0.00814819],\n",
      "       [-0.00015259],\n",
      "       [ 0.01187134]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00674438],\n",
      "       [-0.00338745],\n",
      "       [-0.00482178],\n",
      "       ...,\n",
      "       [ 0.0201416 ],\n",
      "       [ 0.03170776],\n",
      "       [ 0.03933716]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.04043579],\n",
      "       [ 0.02523804],\n",
      "       [-0.01449585],\n",
      "       ...,\n",
      "       [-0.00384521],\n",
      "       [-0.01107788],\n",
      "       [ 0.01651001]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00143433],\n",
      "       [-0.01303101],\n",
      "       [-0.00924683],\n",
      "       ...,\n",
      "       [ 0.02688599],\n",
      "       [-0.00274658],\n",
      "       [ 0.00592041]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01095581],\n",
      "       [-0.0317688 ],\n",
      "       [-0.01242065],\n",
      "       ...,\n",
      "       [ 0.00479126],\n",
      "       [ 0.02182007],\n",
      "       [ 0.01220703]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00024414],\n",
      "       [-0.01199341],\n",
      "       [ 0.01687622],\n",
      "       ...,\n",
      "       [ 0.00280762],\n",
      "       [ 0.02801514],\n",
      "       [ 0.04388428]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 2.4047852e-02],\n",
      "       [ 2.5909424e-02],\n",
      "       [ 4.8614502e-02],\n",
      "       ...,\n",
      "       [ 3.0517578e-05],\n",
      "       [-1.3427734e-03],\n",
      "       [ 2.6855469e-03]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01364136],\n",
      "       [ 0.00106812],\n",
      "       [ 0.01092529],\n",
      "       ...,\n",
      "       [-0.01300049],\n",
      "       [ 0.01031494],\n",
      "       [-0.01461792]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02279663],\n",
      "       [-0.01116943],\n",
      "       [ 0.00112915],\n",
      "       ...,\n",
      "       [ 0.00650024],\n",
      "       [ 0.00350952],\n",
      "       [ 0.01599121]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.02154541],\n",
      "       [0.01980591],\n",
      "       [0.01593018],\n",
      "       ...,\n",
      "       [0.00726318],\n",
      "       [0.01791382],\n",
      "       [0.03393555]], dtype=float32)>] samples generated from 16000_pcm_speeches\\noise\\other\\exercise_bike.wav\n",
      "60 slices, [<tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.6796875 ],\n",
      "       [ 0.32202148],\n",
      "       [ 0.41156006],\n",
      "       ...,\n",
      "       [-0.07870483],\n",
      "       [-0.00308228],\n",
      "       [ 0.1557312 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.12347412],\n",
      "       [-0.0255127 ],\n",
      "       [-0.06317139],\n",
      "       ...,\n",
      "       [ 0.03457642],\n",
      "       [ 0.2083435 ],\n",
      "       [ 0.4513855 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.42971802],\n",
      "       [ 0.2899475 ],\n",
      "       [ 0.40582275],\n",
      "       ...,\n",
      "       [-0.59317017],\n",
      "       [-0.49490356],\n",
      "       [-0.60446167]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.31356812],\n",
      "       [-0.2558899 ],\n",
      "       [-0.54330444],\n",
      "       ...,\n",
      "       [ 0.03283691],\n",
      "       [ 0.14614868],\n",
      "       [-0.0553894 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.07052612],\n",
      "       [-0.09152222],\n",
      "       [-0.38989258],\n",
      "       ...,\n",
      "       [ 0.06283569],\n",
      "       [-0.25958252],\n",
      "       [-0.05108643]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.06781006],\n",
      "       [ 0.22802734],\n",
      "       [ 0.42471313],\n",
      "       ...,\n",
      "       [ 0.31881714],\n",
      "       [-0.07901001],\n",
      "       [ 0.0788269 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.12805176],\n",
      "       [ 0.32629395],\n",
      "       [ 0.22634888],\n",
      "       ...,\n",
      "       [ 0.15258789],\n",
      "       [ 0.24523926],\n",
      "       [-0.0133667 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.2758484 ],\n",
      "       [-0.03094482],\n",
      "       [-0.02017212],\n",
      "       ...,\n",
      "       [ 0.5726929 ],\n",
      "       [ 0.18969727],\n",
      "       [ 0.32891846]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.12661743],\n",
      "       [ 0.03445435],\n",
      "       [-0.18444824],\n",
      "       ...,\n",
      "       [ 0.1487732 ],\n",
      "       [ 0.07196045],\n",
      "       [ 0.01177979]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.16989136],\n",
      "       [0.26174927],\n",
      "       [0.17407227],\n",
      "       ...,\n",
      "       [0.246521  ],\n",
      "       [0.33059692],\n",
      "       [0.35195923]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.43267822],\n",
      "       [ 0.40029907],\n",
      "       [ 0.18499756],\n",
      "       ...,\n",
      "       [-0.05175781],\n",
      "       [ 0.02661133],\n",
      "       [ 0.2338562 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.0206604 ],\n",
      "       [-0.10549927],\n",
      "       [ 0.06298828],\n",
      "       ...,\n",
      "       [ 0.39627075],\n",
      "       [ 0.47595215],\n",
      "       [ 0.45040894]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.256073  ],\n",
      "       [-0.04891968],\n",
      "       [ 0.09896851],\n",
      "       ...,\n",
      "       [-0.2685547 ],\n",
      "       [-0.31356812],\n",
      "       [-0.32357788]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.49118042],\n",
      "       [-0.5043335 ],\n",
      "       [-0.2272644 ],\n",
      "       ...,\n",
      "       [ 0.26763916],\n",
      "       [-0.06298828],\n",
      "       [ 0.09484863]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.08520508],\n",
      "       [ 0.13842773],\n",
      "       [-0.09429932],\n",
      "       ...,\n",
      "       [ 0.40307617],\n",
      "       [ 0.44335938],\n",
      "       [ 0.37945557]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.14196777],\n",
      "       [ 0.14169312],\n",
      "       [ 0.03585815],\n",
      "       ...,\n",
      "       [-0.21206665],\n",
      "       [-0.18984985],\n",
      "       [-0.43634033]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.50323486],\n",
      "       [-0.4503479 ],\n",
      "       [-0.11380005],\n",
      "       ...,\n",
      "       [-0.38986206],\n",
      "       [-0.43875122],\n",
      "       [-0.48898315]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.70544434],\n",
      "       [-0.5787964 ],\n",
      "       [-0.5223999 ],\n",
      "       ...,\n",
      "       [ 0.04525757],\n",
      "       [ 0.16690063],\n",
      "       [-0.10247803]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.19940186],\n",
      "       [-0.05307007],\n",
      "       [ 0.04544067],\n",
      "       ...,\n",
      "       [ 0.30404663],\n",
      "       [ 0.19995117],\n",
      "       [ 0.02072144]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.09274292],\n",
      "       [-0.20144653],\n",
      "       [ 0.05664062],\n",
      "       ...,\n",
      "       [ 0.00927734],\n",
      "       [-0.15826416],\n",
      "       [-0.09191895]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.11245728],\n",
      "       [-0.17712402],\n",
      "       [-0.21676636],\n",
      "       ...,\n",
      "       [ 0.12390137],\n",
      "       [ 0.22616577],\n",
      "       [ 0.09631348]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.07110596],\n",
      "       [0.01754761],\n",
      "       [0.10894775],\n",
      "       ...,\n",
      "       [0.02163696],\n",
      "       [0.19488525],\n",
      "       [0.10971069]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.18182373],\n",
      "       [-0.05923462],\n",
      "       [ 0.06204224],\n",
      "       ...,\n",
      "       [ 0.12005615],\n",
      "       [ 0.36828613],\n",
      "       [ 0.2506714 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.39648438],\n",
      "       [-0.00314331],\n",
      "       [-0.02700806],\n",
      "       ...,\n",
      "       [ 0.29187012],\n",
      "       [ 0.14520264],\n",
      "       [ 0.07299805]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.38394165],\n",
      "       [ 0.18582153],\n",
      "       [ 0.23690796],\n",
      "       ...,\n",
      "       [-0.42147827],\n",
      "       [-0.25756836],\n",
      "       [-0.05249023]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.03387451],\n",
      "       [-0.2062378 ],\n",
      "       [-0.30975342],\n",
      "       ...,\n",
      "       [-0.27416992],\n",
      "       [-0.4503479 ],\n",
      "       [-0.19390869]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.5835571 ],\n",
      "       [-0.6376648 ],\n",
      "       [-0.4734497 ],\n",
      "       ...,\n",
      "       [ 0.08380127],\n",
      "       [ 0.04257202],\n",
      "       [ 0.1156311 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.0826416 ],\n",
      "       [ 0.20898438],\n",
      "       [ 0.20678711],\n",
      "       ...,\n",
      "       [-0.51052856],\n",
      "       [-0.23950195],\n",
      "       [-0.13104248]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.09359741],\n",
      "       [-0.21496582],\n",
      "       [-0.3196106 ],\n",
      "       ...,\n",
      "       [-0.76226807],\n",
      "       [-0.8373413 ],\n",
      "       [-0.591095  ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.77838135],\n",
      "       [-0.63619995],\n",
      "       [-0.28231812],\n",
      "       ...,\n",
      "       [-0.50042725],\n",
      "       [-0.5433655 ],\n",
      "       [-0.67214966]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.8589783 ],\n",
      "       [-0.52615356],\n",
      "       [-0.49975586],\n",
      "       ...,\n",
      "       [ 0.22705078],\n",
      "       [-0.02825928],\n",
      "       [ 0.168396  ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.30993652],\n",
      "       [ 0.25909424],\n",
      "       [-0.00256348],\n",
      "       ...,\n",
      "       [ 0.23757935],\n",
      "       [ 0.2789917 ],\n",
      "       [ 0.23617554]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.5343628 ],\n",
      "       [ 0.16836548],\n",
      "       [ 0.10586548],\n",
      "       ...,\n",
      "       [-0.3798828 ],\n",
      "       [-0.42907715],\n",
      "       [-0.6107483 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.4685669 ],\n",
      "       [-0.339386  ],\n",
      "       [-0.4494934 ],\n",
      "       ...,\n",
      "       [ 0.04208374],\n",
      "       [-0.13143921],\n",
      "       [-0.12792969]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.03710938],\n",
      "       [-0.0904541 ],\n",
      "       [-0.11206055],\n",
      "       ...,\n",
      "       [-0.21554565],\n",
      "       [-0.2987976 ],\n",
      "       [-0.5965576 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.34152222],\n",
      "       [-0.22546387],\n",
      "       [-0.2244873 ],\n",
      "       ...,\n",
      "       [-0.18081665],\n",
      "       [-0.11022949],\n",
      "       [-0.4180298 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.38586426],\n",
      "       [-0.33172607],\n",
      "       [-0.16046143],\n",
      "       ...,\n",
      "       [-0.16152954],\n",
      "       [ 0.01092529],\n",
      "       [ 0.01293945]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00973511],\n",
      "       [-0.06692505],\n",
      "       [-0.39440918],\n",
      "       ...,\n",
      "       [ 0.0223999 ],\n",
      "       [-0.13980103],\n",
      "       [-0.30212402]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.10140991],\n",
      "       [-0.21798706],\n",
      "       [-0.19174194],\n",
      "       ...,\n",
      "       [-0.00360107],\n",
      "       [ 0.05157471],\n",
      "       [ 0.11312866]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.04391479],\n",
      "       [ 0.01245117],\n",
      "       [-0.05438232],\n",
      "       ...,\n",
      "       [-0.27194214],\n",
      "       [-0.30236816],\n",
      "       [-0.6235962 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.5002136 ],\n",
      "       [-0.34875488],\n",
      "       [-0.29864502],\n",
      "       ...,\n",
      "       [ 0.31332397],\n",
      "       [ 0.45785522],\n",
      "       [ 0.51416016]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.4270935 ],\n",
      "       [0.08605957],\n",
      "       [0.04455566],\n",
      "       ...,\n",
      "       [0.4951477 ],\n",
      "       [0.2859192 ],\n",
      "       [0.44345093]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.20220947],\n",
      "       [0.38659668],\n",
      "       [0.32113647],\n",
      "       ...,\n",
      "       [0.21282959],\n",
      "       [0.02435303],\n",
      "       [0.28842163]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.11694336],\n",
      "       [-0.10281372],\n",
      "       [-0.05990601],\n",
      "       ...,\n",
      "       [ 0.03427124],\n",
      "       [ 0.10787964],\n",
      "       [ 0.14407349]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.3284912 ],\n",
      "       [0.10644531],\n",
      "       [0.07223511],\n",
      "       ...,\n",
      "       [0.13931274],\n",
      "       [0.1298523 ],\n",
      "       [0.4008484 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.5169983 ],\n",
      "       [0.62908936],\n",
      "       [0.6130676 ],\n",
      "       ...,\n",
      "       [0.49038696],\n",
      "       [0.69003296],\n",
      "       [0.5476074 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.620697  ],\n",
      "       [0.1998291 ],\n",
      "       [0.49179077],\n",
      "       ...,\n",
      "       [0.06777954],\n",
      "       [0.05941772],\n",
      "       [0.03100586]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01065063],\n",
      "       [-0.0788269 ],\n",
      "       [-0.18804932],\n",
      "       ...,\n",
      "       [ 0.01873779],\n",
      "       [ 0.03262329],\n",
      "       [ 0.1503601 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.05422974],\n",
      "       [-0.1645813 ],\n",
      "       [-0.20993042],\n",
      "       ...,\n",
      "       [-0.08444214],\n",
      "       [-0.14422607],\n",
      "       [-0.16799927]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.12115479],\n",
      "       [-0.08615112],\n",
      "       [-0.0062561 ],\n",
      "       ...,\n",
      "       [ 0.25280762],\n",
      "       [ 0.36437988],\n",
      "       [ 0.21044922]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.26843262],\n",
      "       [ 0.23895264],\n",
      "       [ 0.2263794 ],\n",
      "       ...,\n",
      "       [-0.37374878],\n",
      "       [-0.4095459 ],\n",
      "       [-0.69036865]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.42181396],\n",
      "       [-0.21694946],\n",
      "       [-0.22369385],\n",
      "       ...,\n",
      "       [ 0.14511108],\n",
      "       [ 0.05804443],\n",
      "       [ 0.00866699]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.16381836],\n",
      "       [-0.06088257],\n",
      "       [ 0.0982666 ],\n",
      "       ...,\n",
      "       [ 0.28051758],\n",
      "       [ 0.40838623],\n",
      "       [ 0.41671753]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.03314209],\n",
      "       [ 0.30758667],\n",
      "       [ 0.19998169],\n",
      "       ...,\n",
      "       [-0.07315063],\n",
      "       [-0.15960693],\n",
      "       [ 0.07305908]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.09637451],\n",
      "       [-0.10177612],\n",
      "       [-0.23406982],\n",
      "       ...,\n",
      "       [-0.19818115],\n",
      "       [-0.03549194],\n",
      "       [ 0.01370239]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.04400635],\n",
      "       [ 0.08956909],\n",
      "       [ 0.15203857],\n",
      "       ...,\n",
      "       [-0.5158386 ],\n",
      "       [-0.8446655 ],\n",
      "       [-0.6139221 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.63223267],\n",
      "       [-0.6961365 ],\n",
      "       [-0.7576294 ],\n",
      "       ...,\n",
      "       [-0.19726562],\n",
      "       [ 0.05374146],\n",
      "       [ 0.12823486]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.2899475 ],\n",
      "       [ 0.2989502 ],\n",
      "       [ 0.09075928],\n",
      "       ...,\n",
      "       [-0.04669189],\n",
      "       [ 0.13934326],\n",
      "       [ 0.22766113]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.2008667 ],\n",
      "       [-0.06356812],\n",
      "       [-0.09030151],\n",
      "       ...,\n",
      "       [ 0.09179688],\n",
      "       [ 0.07131958],\n",
      "       [ 0.1000061 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.31246948],\n",
      "       [0.3852234 ],\n",
      "       [0.13287354],\n",
      "       ...,\n",
      "       [0.41967773],\n",
      "       [0.31045532],\n",
      "       [0.47058105]], dtype=float32)>] samples generated from 16000_pcm_speeches\\noise\\other\\pink_noise.wav\n",
      "16 slices, [<tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-6.1035156e-05],\n",
      "       [ 9.1552734e-05],\n",
      "       [ 1.2207031e-04],\n",
      "       ...,\n",
      "       [ 3.0517578e-05],\n",
      "       [ 3.0517578e-05],\n",
      "       [ 0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 6.1035156e-05],\n",
      "       [-6.1035156e-05],\n",
      "       [-6.1035156e-05],\n",
      "       ...,\n",
      "       [ 3.0517578e-05],\n",
      "       [ 3.0517578e-05],\n",
      "       [ 3.0517578e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 3.0517578e-05],\n",
      "       [ 0.0000000e+00],\n",
      "       [ 0.0000000e+00],\n",
      "       ...,\n",
      "       [ 0.0000000e+00],\n",
      "       [-6.1035156e-05],\n",
      "       [-6.1035156e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-3.0517578e-05],\n",
      "       [ 3.0517578e-05],\n",
      "       [ 9.1552734e-05],\n",
      "       ...,\n",
      "       [-6.1035156e-05],\n",
      "       [-6.1035156e-05],\n",
      "       [-9.1552734e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-9.1552734e-05],\n",
      "       [-9.1552734e-05],\n",
      "       [-9.1552734e-05],\n",
      "       ...,\n",
      "       [ 0.0000000e+00],\n",
      "       [ 0.0000000e+00],\n",
      "       [ 0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-3.0517578e-05],\n",
      "       [ 0.0000000e+00],\n",
      "       [ 0.0000000e+00],\n",
      "       ...,\n",
      "       [ 9.1552734e-05],\n",
      "       [ 3.0517578e-05],\n",
      "       [ 3.0517578e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 3.0517578e-05],\n",
      "       [ 3.0517578e-05],\n",
      "       [ 3.0517578e-05],\n",
      "       ...,\n",
      "       [-3.0517578e-05],\n",
      "       [ 3.0517578e-05],\n",
      "       [ 3.0517578e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00],\n",
      "       [ 3.0517578e-05],\n",
      "       [ 6.1035156e-05],\n",
      "       ...,\n",
      "       [-6.1035156e-05],\n",
      "       [-9.1552734e-05],\n",
      "       [-6.1035156e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 3.0517578e-05],\n",
      "       [-3.0517578e-05],\n",
      "       [-3.0517578e-05],\n",
      "       ...,\n",
      "       [ 9.1552734e-05],\n",
      "       [ 3.0517578e-05],\n",
      "       [-3.0517578e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-6.1035156e-05],\n",
      "       [-6.1035156e-05],\n",
      "       [ 0.0000000e+00],\n",
      "       ...,\n",
      "       [-2.6428223e-02],\n",
      "       [ 3.2043457e-03],\n",
      "       [ 3.4240723e-02]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.04998779],\n",
      "       [ 0.0305481 ],\n",
      "       [-0.01229858],\n",
      "       ...,\n",
      "       [ 0.0267334 ],\n",
      "       [-0.00177002],\n",
      "       [-0.01626587]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00564575],\n",
      "       [ 0.01986694],\n",
      "       [ 0.03720093],\n",
      "       ...,\n",
      "       [-0.08468628],\n",
      "       [-0.08349609],\n",
      "       [-0.0663147 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02731323],\n",
      "       [ 0.01748657],\n",
      "       [ 0.04034424],\n",
      "       ...,\n",
      "       [ 0.05142212],\n",
      "       [ 0.08901978],\n",
      "       [ 0.08276367]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.04284668],\n",
      "       [ 0.00845337],\n",
      "       [-0.00296021],\n",
      "       ...,\n",
      "       [ 0.03219604],\n",
      "       [-0.00515747],\n",
      "       [-0.03042603]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.04034424],\n",
      "       [-0.04818726],\n",
      "       [-0.05633545],\n",
      "       ...,\n",
      "       [ 0.00631714],\n",
      "       [ 0.03829956],\n",
      "       [ 0.02713013]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02148438],\n",
      "       [-0.05950928],\n",
      "       [-0.05187988],\n",
      "       ...,\n",
      "       [-0.00717163],\n",
      "       [-0.01553345],\n",
      "       [-0.01739502]], dtype=float32)>] samples generated from 16000_pcm_speeches\\noise\\_background_noise_\\10convert.com_Audience-Claps_daSG5fwdA7o.wav\n",
      "95 slices, [<tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       ...,\n",
      "       [-0.00357056],\n",
      "       [-0.0255127 ],\n",
      "       [-0.04653931]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.06082153],\n",
      "       [-0.05145264],\n",
      "       [-0.08868408],\n",
      "       ...,\n",
      "       [ 0.02459717],\n",
      "       [ 0.01550293],\n",
      "       [-0.02416992]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.04968262],\n",
      "       [-0.02111816],\n",
      "       [ 0.03253174],\n",
      "       ...,\n",
      "       [ 0.02362061],\n",
      "       [ 0.03955078],\n",
      "       [ 0.05682373]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.08041382],\n",
      "       [ 0.0453186 ],\n",
      "       [ 0.02102661],\n",
      "       ...,\n",
      "       [ 0.02520752],\n",
      "       [ 0.00027466],\n",
      "       [-0.02453613]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.05459595],\n",
      "       [-0.06939697],\n",
      "       [-0.04089355],\n",
      "       ...,\n",
      "       [-0.02288818],\n",
      "       [-0.01968384],\n",
      "       [ 0.00640869]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02258301],\n",
      "       [ 0.05731201],\n",
      "       [ 0.10424805],\n",
      "       ...,\n",
      "       [ 0.02026367],\n",
      "       [ 0.01107788],\n",
      "       [-0.02740479]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02996826],\n",
      "       [-0.0447998 ],\n",
      "       [-0.07571411],\n",
      "       ...,\n",
      "       [ 0.03622437],\n",
      "       [-0.02191162],\n",
      "       [-0.06167603]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.03112793],\n",
      "       [-0.00845337],\n",
      "       [-0.01702881],\n",
      "       ...,\n",
      "       [-0.00775146],\n",
      "       [ 0.00015259],\n",
      "       [-0.02804565]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01663208],\n",
      "       [-0.0149231 ],\n",
      "       [-0.01937866],\n",
      "       ...,\n",
      "       [-0.006073  ],\n",
      "       [-0.03286743],\n",
      "       [-0.00695801]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00253296],\n",
      "       [-0.01849365],\n",
      "       [-0.01116943],\n",
      "       ...,\n",
      "       [ 0.02059937],\n",
      "       [-0.0133667 ],\n",
      "       [-0.00631714]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00488281],\n",
      "       [-0.01416016],\n",
      "       [ 0.00961304],\n",
      "       ...,\n",
      "       [-0.01348877],\n",
      "       [-0.03314209],\n",
      "       [-0.01477051]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01470947],\n",
      "       [-0.0050354 ],\n",
      "       [-0.01629639],\n",
      "       ...,\n",
      "       [ 0.07138062],\n",
      "       [ 0.07403564],\n",
      "       [ 0.03738403]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.04266357],\n",
      "       [-0.04193115],\n",
      "       [-0.03427124],\n",
      "       ...,\n",
      "       [-0.02630615],\n",
      "       [-0.0244751 ],\n",
      "       [-0.02398682]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01455688],\n",
      "       [ 0.00109863],\n",
      "       [-0.00286865],\n",
      "       ...,\n",
      "       [-0.02920532],\n",
      "       [ 0.00384521],\n",
      "       [ 0.00192261]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02374268],\n",
      "       [ 0.01031494],\n",
      "       [-0.00094604],\n",
      "       ...,\n",
      "       [ 0.00680542],\n",
      "       [ 0.0531311 ],\n",
      "       [ 0.00183105]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01202393],\n",
      "       [-0.00482178],\n",
      "       [ 0.01239014],\n",
      "       ...,\n",
      "       [ 0.01272583],\n",
      "       [ 0.00866699],\n",
      "       [ 0.00872803]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00073242],\n",
      "       [ 0.00177002],\n",
      "       [-0.02044678],\n",
      "       ...,\n",
      "       [-0.02584839],\n",
      "       [-0.01257324],\n",
      "       [ 0.0022583 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.06188965],\n",
      "       [ 0.10443115],\n",
      "       [ 0.0697937 ],\n",
      "       ...,\n",
      "       [-0.00515747],\n",
      "       [ 0.00131226],\n",
      "       [-0.00628662]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.03710938],\n",
      "       [-0.04629517],\n",
      "       [-0.07333374],\n",
      "       ...,\n",
      "       [-0.03762817],\n",
      "       [-0.06365967],\n",
      "       [-0.05661011]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00579834],\n",
      "       [-0.00112915],\n",
      "       [ 0.01843262],\n",
      "       ...,\n",
      "       [-0.01409912],\n",
      "       [-0.00756836],\n",
      "       [ 0.05136108]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.05004883],\n",
      "       [ 0.01638794],\n",
      "       [ 0.00695801],\n",
      "       ...,\n",
      "       [-0.01318359],\n",
      "       [-0.01141357],\n",
      "       [ 0.00076294]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01577759],\n",
      "       [ 0.03225708],\n",
      "       [-0.00216675],\n",
      "       ...,\n",
      "       [ 0.09890747],\n",
      "       [ 0.06393433],\n",
      "       [ 0.04580688]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00216675],\n",
      "       [-0.07232666],\n",
      "       [-0.10845947],\n",
      "       ...,\n",
      "       [ 0.06079102],\n",
      "       [ 0.04605103],\n",
      "       [ 0.0022583 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00720215],\n",
      "       [-0.02990723],\n",
      "       [-0.02456665],\n",
      "       ...,\n",
      "       [ 0.01004028],\n",
      "       [ 0.01193237],\n",
      "       [ 0.04147339]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.05874634],\n",
      "       [0.06185913],\n",
      "       [0.04159546],\n",
      "       ...,\n",
      "       [0.0279541 ],\n",
      "       [0.03427124],\n",
      "       [0.03363037]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.04367065],\n",
      "       [0.04772949],\n",
      "       [0.02987671],\n",
      "       ...,\n",
      "       [0.19546509],\n",
      "       [0.1531372 ],\n",
      "       [0.08322144]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00497437],\n",
      "       [-0.05401611],\n",
      "       [-0.11199951],\n",
      "       ...,\n",
      "       [-0.00891113],\n",
      "       [ 0.00500488],\n",
      "       [-0.00744629]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02987671],\n",
      "       [-0.0395813 ],\n",
      "       [-0.06958008],\n",
      "       ...,\n",
      "       [-0.04928589],\n",
      "       [-0.03292847],\n",
      "       [-0.02249146]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.0149231 ],\n",
      "       [0.06045532],\n",
      "       [0.07495117],\n",
      "       ...,\n",
      "       [0.04504395],\n",
      "       [0.06570435],\n",
      "       [0.03305054]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01702881],\n",
      "       [ 0.01638794],\n",
      "       [-0.02435303],\n",
      "       ...,\n",
      "       [ 0.00198364],\n",
      "       [ 0.02560425],\n",
      "       [ 0.04760742]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.05053711],\n",
      "       [ 0.0223999 ],\n",
      "       [ 0.01989746],\n",
      "       ...,\n",
      "       [-0.01190186],\n",
      "       [-0.00765991],\n",
      "       [ 0.00244141]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.02688599],\n",
      "       [0.02093506],\n",
      "       [0.01095581],\n",
      "       ...,\n",
      "       [0.06997681],\n",
      "       [0.05349731],\n",
      "       [0.04736328]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00549316],\n",
      "       [-0.02200317],\n",
      "       [-0.03500366],\n",
      "       ...,\n",
      "       [ 0.0093689 ],\n",
      "       [-0.0032959 ],\n",
      "       [-0.0256958 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.05361938],\n",
      "       [-0.03271484],\n",
      "       [ 0.00143433],\n",
      "       ...,\n",
      "       [ 0.07427979],\n",
      "       [ 0.0788269 ],\n",
      "       [ 0.07861328]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.09469604],\n",
      "       [ 0.09121704],\n",
      "       [ 0.09448242],\n",
      "       ...,\n",
      "       [-0.00494385],\n",
      "       [-0.0335083 ],\n",
      "       [-0.04916382]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.05856323],\n",
      "       [-0.06564331],\n",
      "       [-0.05221558],\n",
      "       ...,\n",
      "       [-0.00283813],\n",
      "       [-0.00802612],\n",
      "       [-0.0145874 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00097656],\n",
      "       [ 0.00076294],\n",
      "       [-0.00671387],\n",
      "       ...,\n",
      "       [ 0.01712036],\n",
      "       [ 0.0161438 ],\n",
      "       [ 0.00634766]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00610352],\n",
      "       [ 0.01092529],\n",
      "       [ 0.00115967],\n",
      "       ...,\n",
      "       [-0.03460693],\n",
      "       [ 0.08203125],\n",
      "       [ 0.03564453]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00192261],\n",
      "       [ 0.01397705],\n",
      "       [ 0.3585205 ],\n",
      "       ...,\n",
      "       [-0.00192261],\n",
      "       [-0.00634766],\n",
      "       [-0.01013184]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00210571],\n",
      "       [-0.00045776],\n",
      "       [-0.00689697],\n",
      "       ...,\n",
      "       [-0.02227783],\n",
      "       [ 0.0088501 ],\n",
      "       [ 0.01086426]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02310181],\n",
      "       [ 0.00125122],\n",
      "       [ 0.01077271],\n",
      "       ...,\n",
      "       [-0.01193237],\n",
      "       [-0.00982666],\n",
      "       [-0.00912476]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01876831],\n",
      "       [-0.01190186],\n",
      "       [ 0.0149231 ],\n",
      "       ...,\n",
      "       [ 0.05319214],\n",
      "       [ 0.00247192],\n",
      "       [ 0.03082275]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00601196],\n",
      "       [-0.01339722],\n",
      "       [-0.03335571],\n",
      "       ...,\n",
      "       [ 0.01416016],\n",
      "       [ 0.02871704],\n",
      "       [ 0.03872681]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02996826],\n",
      "       [ 0.00497437],\n",
      "       [-0.02371216],\n",
      "       ...,\n",
      "       [ 0.00878906],\n",
      "       [ 0.01062012],\n",
      "       [ 0.00775146]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.0213623 ],\n",
      "       [ 0.02484131],\n",
      "       [ 0.03268433],\n",
      "       ...,\n",
      "       [-0.03161621],\n",
      "       [-0.03219604],\n",
      "       [-0.02532959]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02719116],\n",
      "       [-0.01202393],\n",
      "       [-0.00668335],\n",
      "       ...,\n",
      "       [-0.02078247],\n",
      "       [-0.04000854],\n",
      "       [-0.03890991]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.03930664],\n",
      "       [-0.03991699],\n",
      "       [-0.03433228],\n",
      "       ...,\n",
      "       [ 0.02407837],\n",
      "       [ 0.0163269 ],\n",
      "       [ 0.01312256]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00561523],\n",
      "       [-0.00653076],\n",
      "       [-0.00128174],\n",
      "       ...,\n",
      "       [-0.01248169],\n",
      "       [-0.00042725],\n",
      "       [ 0.00341797]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00161743],\n",
      "       [-0.01208496],\n",
      "       [-0.02258301],\n",
      "       ...,\n",
      "       [ 0.02160645],\n",
      "       [ 0.00967407],\n",
      "       [ 0.00640869]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-2.6306152e-02],\n",
      "       [-1.0559082e-02],\n",
      "       [-1.5777588e-02],\n",
      "       ...,\n",
      "       [-4.2724609e-04],\n",
      "       [-4.1809082e-03],\n",
      "       [ 3.0517578e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.01516724],\n",
      "       [0.02825928],\n",
      "       [0.02868652],\n",
      "       ...,\n",
      "       [0.02365112],\n",
      "       [0.01330566],\n",
      "       [0.00747681]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.02236938],\n",
      "       [0.02877808],\n",
      "       [0.0267334 ],\n",
      "       ...,\n",
      "       [0.1494751 ],\n",
      "       [0.11413574],\n",
      "       [0.14950562]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.10211182],\n",
      "       [ 0.05844116],\n",
      "       [ 0.0713501 ],\n",
      "       ...,\n",
      "       [-0.00128174],\n",
      "       [ 0.00592041],\n",
      "       [ 0.01898193]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.03369141],\n",
      "       [ 0.02505493],\n",
      "       [ 0.02825928],\n",
      "       ...,\n",
      "       [-0.0196228 ],\n",
      "       [-0.02294922],\n",
      "       [-0.04095459]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.0585022 ],\n",
      "       [-0.05484009],\n",
      "       [-0.04571533],\n",
      "       ...,\n",
      "       [ 0.02197266],\n",
      "       [ 0.01779175],\n",
      "       [ 0.00830078]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00891113],\n",
      "       [-0.01690674],\n",
      "       [-0.0144043 ],\n",
      "       ...,\n",
      "       [ 0.00064087],\n",
      "       [-0.02868652],\n",
      "       [-0.04293823]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.0451355 ],\n",
      "       [-0.05209351],\n",
      "       [-0.05484009],\n",
      "       ...,\n",
      "       [-0.04229736],\n",
      "       [-0.02862549],\n",
      "       [-0.02819824]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02658081],\n",
      "       [-0.02828979],\n",
      "       [-0.02197266],\n",
      "       ...,\n",
      "       [-0.02526855],\n",
      "       [-0.01681519],\n",
      "       [ 0.01275635]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.02474976],\n",
      "       [0.04873657],\n",
      "       [0.04257202],\n",
      "       ...,\n",
      "       [0.0295105 ],\n",
      "       [0.02639771],\n",
      "       [0.03305054]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02203369],\n",
      "       [-0.01315308],\n",
      "       [-0.0206604 ],\n",
      "       ...,\n",
      "       [-0.03860474],\n",
      "       [-0.03738403],\n",
      "       [-0.03457642]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02749634],\n",
      "       [-0.00872803],\n",
      "       [ 0.01977539],\n",
      "       ...,\n",
      "       [ 0.03729248],\n",
      "       [ 0.03491211],\n",
      "       [ 0.05197144]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.06536865],\n",
      "       [0.05184937],\n",
      "       [0.05270386],\n",
      "       ...,\n",
      "       [0.05148315],\n",
      "       [0.02130127],\n",
      "       [0.00793457]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01361084],\n",
      "       [-0.02490234],\n",
      "       [-0.02359009],\n",
      "       ...,\n",
      "       [-0.01062012],\n",
      "       [ 0.00415039],\n",
      "       [ 0.01321411]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.012146  ],\n",
      "       [0.03869629],\n",
      "       [0.04467773],\n",
      "       ...,\n",
      "       [0.03363037],\n",
      "       [0.03665161],\n",
      "       [0.02584839]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.03274536],\n",
      "       [ 0.02203369],\n",
      "       [ 0.00180054],\n",
      "       ...,\n",
      "       [-0.0632019 ],\n",
      "       [-0.05728149],\n",
      "       [-0.02841187]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00378418],\n",
      "       [ 0.00476074],\n",
      "       [ 0.02526855],\n",
      "       ...,\n",
      "       [-0.00195312],\n",
      "       [-0.01239014],\n",
      "       [-0.01312256]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.0098877 ],\n",
      "       [-0.00939941],\n",
      "       [-0.00637817],\n",
      "       ...,\n",
      "       [ 0.02511597],\n",
      "       [ 0.04574585],\n",
      "       [ 0.05371094]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.04724121],\n",
      "       [0.04229736],\n",
      "       [0.04675293],\n",
      "       ...,\n",
      "       [0.02209473],\n",
      "       [0.01882935],\n",
      "       [0.01010132]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00454712],\n",
      "       [-0.01391602],\n",
      "       [-0.0105896 ],\n",
      "       ...,\n",
      "       [ 0.03070068],\n",
      "       [ 0.02954102],\n",
      "       [ 0.02825928]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.02429199],\n",
      "       [0.0144043 ],\n",
      "       [0.00759888],\n",
      "       ...,\n",
      "       [0.00231934],\n",
      "       [0.01834106],\n",
      "       [0.02609253]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.0291748 ],\n",
      "       [ 0.03063965],\n",
      "       [ 0.02383423],\n",
      "       ...,\n",
      "       [-0.03771973],\n",
      "       [-0.0269165 ],\n",
      "       [-0.02096558]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01647949],\n",
      "       [-0.01083374],\n",
      "       [-0.00436401],\n",
      "       ...,\n",
      "       [ 0.0335083 ],\n",
      "       [ 0.02261353],\n",
      "       [ 0.01348877]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01052856],\n",
      "       [-0.00152588],\n",
      "       [-0.01580811],\n",
      "       ...,\n",
      "       [-0.0770874 ],\n",
      "       [-0.07839966],\n",
      "       [-0.08276367]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.06906128],\n",
      "       [-0.05487061],\n",
      "       [-0.04400635],\n",
      "       ...,\n",
      "       [-0.0133667 ],\n",
      "       [-0.01034546],\n",
      "       [-0.00509644]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00946045],\n",
      "       [-0.01348877],\n",
      "       [-0.02072144],\n",
      "       ...,\n",
      "       [ 0.0340271 ],\n",
      "       [ 0.02639771],\n",
      "       [ 0.02008057]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01806641],\n",
      "       [ 0.01019287],\n",
      "       [ 0.00180054],\n",
      "       ...,\n",
      "       [-0.02139282],\n",
      "       [-0.03152466],\n",
      "       [-0.03689575]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.04104614],\n",
      "       [-0.04043579],\n",
      "       [-0.03488159],\n",
      "       ...,\n",
      "       [ 0.02185059],\n",
      "       [ 0.01434326],\n",
      "       [ 0.0065918 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00839233],\n",
      "       [-0.01800537],\n",
      "       [-0.0196228 ],\n",
      "       ...,\n",
      "       [ 0.03256226],\n",
      "       [ 0.03567505],\n",
      "       [ 0.0335083 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.04049683],\n",
      "       [ 0.04119873],\n",
      "       [ 0.03436279],\n",
      "       ...,\n",
      "       [-0.02069092],\n",
      "       [-0.02160645],\n",
      "       [-0.02050781]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.0144043 ],\n",
      "       [-0.01052856],\n",
      "       [-0.01101685],\n",
      "       ...,\n",
      "       [-0.01699829],\n",
      "       [-0.0199585 ],\n",
      "       [-0.02429199]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.027771  ],\n",
      "       [-0.02612305],\n",
      "       [-0.01922607],\n",
      "       ...,\n",
      "       [-0.0007019 ],\n",
      "       [-0.01089478],\n",
      "       [-0.01834106]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02053833],\n",
      "       [-0.02133179],\n",
      "       [-0.02935791],\n",
      "       ...,\n",
      "       [ 0.00558472],\n",
      "       [-0.00305176],\n",
      "       [-0.00354004]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.0065918 ],\n",
      "       [-0.0098877 ],\n",
      "       [-0.01202393],\n",
      "       ...,\n",
      "       [-0.01293945],\n",
      "       [-0.01339722],\n",
      "       [-0.00775146]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00714111],\n",
      "       [-0.00299072],\n",
      "       [ 0.        ],\n",
      "       ...,\n",
      "       [ 0.00799561],\n",
      "       [ 0.00967407],\n",
      "       [ 0.0133667 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.01074219],\n",
      "       [0.00961304],\n",
      "       [0.01577759],\n",
      "       ...,\n",
      "       [0.00506592],\n",
      "       [0.00567627],\n",
      "       [0.00408936]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 1.1596680e-03],\n",
      "       [ 6.1035156e-05],\n",
      "       [-1.1596680e-03],\n",
      "       ...,\n",
      "       [-7.9345703e-03],\n",
      "       [-9.0637207e-03],\n",
      "       [-6.1340332e-03]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.0020752 ],\n",
      "       [ 0.00030518],\n",
      "       [-0.00231934],\n",
      "       ...,\n",
      "       [ 0.01269531],\n",
      "       [ 0.01370239],\n",
      "       [ 0.01464844]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.0145874 ],\n",
      "       [0.01724243],\n",
      "       [0.01794434],\n",
      "       ...,\n",
      "       [0.01068115],\n",
      "       [0.01098633],\n",
      "       [0.01077271]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00747681],\n",
      "       [ 0.00921631],\n",
      "       [ 0.00741577],\n",
      "       ...,\n",
      "       [-0.00543213],\n",
      "       [-0.01123047],\n",
      "       [-0.01589966]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01776123],\n",
      "       [-0.02026367],\n",
      "       [-0.02514648],\n",
      "       ...,\n",
      "       [ 0.00827026],\n",
      "       [ 0.01315308],\n",
      "       [ 0.01580811]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.0128479 ],\n",
      "       [0.01156616],\n",
      "       [0.00942993],\n",
      "       ...,\n",
      "       [0.00308228],\n",
      "       [0.00338745],\n",
      "       [0.00421143]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.00457764],\n",
      "       [0.00305176],\n",
      "       [0.00216675],\n",
      "       ...,\n",
      "       [0.02401733],\n",
      "       [0.02230835],\n",
      "       [0.02325439]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02407837],\n",
      "       [ 0.02102661],\n",
      "       [ 0.01956177],\n",
      "       ...,\n",
      "       [-0.00149536],\n",
      "       [-0.00332642],\n",
      "       [-0.00027466]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00363159],\n",
      "       [-0.00335693],\n",
      "       [-0.00222778],\n",
      "       ...,\n",
      "       [ 0.00170898],\n",
      "       [ 0.00476074],\n",
      "       [ 0.00759888]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.01052856],\n",
      "       [0.00650024],\n",
      "       [0.00421143],\n",
      "       ...,\n",
      "       [0.00299072],\n",
      "       [0.00610352],\n",
      "       [0.00756836]], dtype=float32)>] samples generated from 16000_pcm_speeches\\noise\\_background_noise_\\doing_the_dishes.wav\n",
      "61 slices, [<tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.00140381],\n",
      "       [0.00131226],\n",
      "       [0.00039673]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 9.1552734e-05],\n",
      "       [ 3.0517578e-05],\n",
      "       [-8.8500977e-04],\n",
      "       ...,\n",
      "       [-1.1596680e-03],\n",
      "       [ 2.1362305e-04],\n",
      "       [ 2.0446777e-03]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00085449],\n",
      "       [-0.00097656],\n",
      "       [-0.0007019 ],\n",
      "       ...,\n",
      "       [-0.0015564 ],\n",
      "       [-0.00140381],\n",
      "       [-0.00018311]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-9.1552734e-05],\n",
      "       [ 0.0000000e+00],\n",
      "       [ 6.7138672e-04],\n",
      "       ...,\n",
      "       [-2.6245117e-03],\n",
      "       [-2.2277832e-03],\n",
      "       [-1.0375977e-03]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00057983],\n",
      "       [ 0.00238037],\n",
      "       [ 0.00231934],\n",
      "       ...,\n",
      "       [ 0.00521851],\n",
      "       [ 0.00302124],\n",
      "       [ 0.00210571]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00128174],\n",
      "       [ 0.00247192],\n",
      "       [-0.0007019 ],\n",
      "       ...,\n",
      "       [ 0.00076294],\n",
      "       [ 0.0012207 ],\n",
      "       [ 0.00079346]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 1.2207031e-03],\n",
      "       [ 1.4343262e-03],\n",
      "       [ 1.0681152e-03],\n",
      "       ...,\n",
      "       [-2.0141602e-03],\n",
      "       [-2.4108887e-03],\n",
      "       [ 9.1552734e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-1.7089844e-03],\n",
      "       [-2.7770996e-03],\n",
      "       [-2.1057129e-03],\n",
      "       ...,\n",
      "       [-3.3569336e-04],\n",
      "       [ 3.9672852e-04],\n",
      "       [ 3.0517578e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00015259],\n",
      "       [ 0.00036621],\n",
      "       [-0.00015259],\n",
      "       ...,\n",
      "       [ 0.00054932],\n",
      "       [ 0.00100708],\n",
      "       [ 0.00177002]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00137329],\n",
      "       [-0.00027466],\n",
      "       [-0.00012207],\n",
      "       ...,\n",
      "       [-0.0010376 ],\n",
      "       [-0.00152588],\n",
      "       [ 0.00057983]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-1.4343262e-03],\n",
      "       [-1.0070801e-03],\n",
      "       [ 2.1362305e-04],\n",
      "       ...,\n",
      "       [-6.1035156e-05],\n",
      "       [ 8.8500977e-04],\n",
      "       [ 4.5776367e-04]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00357056],\n",
      "       [ 0.00375366],\n",
      "       [ 0.00036621],\n",
      "       ...,\n",
      "       [-0.00744629],\n",
      "       [-0.00738525],\n",
      "       [-0.00769043]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00744629],\n",
      "       [-0.00683594],\n",
      "       [-0.00738525],\n",
      "       ...,\n",
      "       [ 0.01296997],\n",
      "       [ 0.00308228],\n",
      "       [ 0.00384521]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00469971],\n",
      "       [ 0.00152588],\n",
      "       [ 0.00439453],\n",
      "       ...,\n",
      "       [ 0.0015564 ],\n",
      "       [-0.00262451],\n",
      "       [ 0.00170898]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00384521],\n",
      "       [ 0.0010376 ],\n",
      "       [-0.00112915],\n",
      "       ...,\n",
      "       [ 0.0017395 ],\n",
      "       [-0.00012207],\n",
      "       [-0.00027466]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00100708],\n",
      "       [ 0.00195312],\n",
      "       [ 0.00131226],\n",
      "       ...,\n",
      "       [ 0.00021362],\n",
      "       [-0.00231934],\n",
      "       [-0.00076294]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00082397],\n",
      "       [-0.00088501],\n",
      "       [ 0.00289917],\n",
      "       ...,\n",
      "       [-0.00125122],\n",
      "       [ 0.00048828],\n",
      "       [ 0.00259399]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-9.1552734e-05],\n",
      "       [-1.8005371e-03],\n",
      "       [ 9.4604492e-04],\n",
      "       ...,\n",
      "       [ 2.4108887e-03],\n",
      "       [ 1.2512207e-03],\n",
      "       [-3.0517578e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00286865],\n",
      "       [ 0.00045776],\n",
      "       [ 0.00024414],\n",
      "       ...,\n",
      "       [-0.12179565],\n",
      "       [-0.00518799],\n",
      "       [ 0.13223267]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00534058],\n",
      "       [-0.0692749 ],\n",
      "       [ 0.05065918],\n",
      "       ...,\n",
      "       [ 0.0022583 ],\n",
      "       [ 0.00192261],\n",
      "       [-0.00027466]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00085449],\n",
      "       [ 0.00054932],\n",
      "       [ 0.00085449],\n",
      "       ...,\n",
      "       [-0.00161743],\n",
      "       [-0.00262451],\n",
      "       [-0.00360107]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00198364],\n",
      "       [-0.00228882],\n",
      "       [-0.0039978 ],\n",
      "       ...,\n",
      "       [-0.00036621],\n",
      "       [ 0.00054932],\n",
      "       [-0.00112915]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.0012207 ],\n",
      "       [-0.00143433],\n",
      "       [-0.00091553],\n",
      "       ...,\n",
      "       [ 0.00094604],\n",
      "       [-0.00100708],\n",
      "       [ 0.0038147 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00201416],\n",
      "       [-0.00186157],\n",
      "       [-0.0022583 ],\n",
      "       ...,\n",
      "       [ 0.00076294],\n",
      "       [ 0.00024414],\n",
      "       [-0.00128174]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00143433],\n",
      "       [-0.00039673],\n",
      "       [ 0.00033569],\n",
      "       ...,\n",
      "       [ 0.00152588],\n",
      "       [ 0.00201416],\n",
      "       [ 0.00219727]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00161743],\n",
      "       [ 0.0010376 ],\n",
      "       [ 0.00091553],\n",
      "       ...,\n",
      "       [-0.0005188 ],\n",
      "       [-0.00192261],\n",
      "       [ 0.00613403]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00604248],\n",
      "       [ 0.00216675],\n",
      "       [-0.0007019 ],\n",
      "       ...,\n",
      "       [ 0.00180054],\n",
      "       [ 0.00216675],\n",
      "       [ 0.00042725]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00283813],\n",
      "       [ 0.00393677],\n",
      "       [ 0.00375366],\n",
      "       ...,\n",
      "       [ 0.00524902],\n",
      "       [-0.00015259],\n",
      "       [-0.00097656]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00082397],\n",
      "       [-0.00527954],\n",
      "       [ 0.00045776],\n",
      "       ...,\n",
      "       [ 0.00027466],\n",
      "       [-0.00067139],\n",
      "       [-0.00201416]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.00161743],\n",
      "       [0.00805664],\n",
      "       [0.00180054],\n",
      "       ...,\n",
      "       [0.00106812],\n",
      "       [0.00283813],\n",
      "       [0.0005188 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00048828],\n",
      "       [-0.00161743],\n",
      "       [-0.00195312],\n",
      "       ...,\n",
      "       [ 0.00308228],\n",
      "       [ 0.00064087],\n",
      "       [ 0.00131226]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-1.2207031e-04],\n",
      "       [ 3.0517578e-05],\n",
      "       [ 5.1879883e-04],\n",
      "       ...,\n",
      "       [ 1.5258789e-03],\n",
      "       [ 2.9602051e-03],\n",
      "       [ 2.2888184e-03]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-3.0517578e-05],\n",
      "       [ 1.3427734e-03],\n",
      "       [ 2.1667480e-03],\n",
      "       ...,\n",
      "       [ 1.4038086e-03],\n",
      "       [ 2.1057129e-03],\n",
      "       [ 8.8500977e-04]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 2.4108887e-03],\n",
      "       [ 3.1127930e-03],\n",
      "       [ 3.2043457e-03],\n",
      "       ...,\n",
      "       [-9.1552734e-05],\n",
      "       [-1.0070801e-03],\n",
      "       [ 5.7983398e-04]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.0027771 ],\n",
      "       [-0.0007019 ],\n",
      "       [ 0.00195312],\n",
      "       ...,\n",
      "       [ 0.00018311],\n",
      "       [ 0.00073242],\n",
      "       [ 0.00076294]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.0000000e+00],\n",
      "       [ 1.2817383e-03],\n",
      "       [-3.0517578e-05],\n",
      "       ...,\n",
      "       [ 1.6174316e-03],\n",
      "       [ 2.7465820e-04],\n",
      "       [ 1.0681152e-03]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00247192],\n",
      "       [ 0.00057983],\n",
      "       [-0.0007019 ],\n",
      "       ...,\n",
      "       [-0.00064087],\n",
      "       [ 0.0005188 ],\n",
      "       [ 0.0015564 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00061035],\n",
      "       [ 0.00030518],\n",
      "       [ 0.00057983],\n",
      "       ...,\n",
      "       [-0.0015564 ],\n",
      "       [ 0.00195312],\n",
      "       [-0.00314331]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-7.9345703e-04],\n",
      "       [ 9.1552734e-05],\n",
      "       [ 3.6621094e-04],\n",
      "       ...,\n",
      "       [ 7.6293945e-04],\n",
      "       [ 8.2397461e-04],\n",
      "       [-4.8828125e-04]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.0007019 ],\n",
      "       [ 0.00140381],\n",
      "       [ 0.00024414],\n",
      "       ...,\n",
      "       [ 0.00109863],\n",
      "       [ 0.00088501],\n",
      "       [-0.00131226]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00045776],\n",
      "       [-0.00045776],\n",
      "       [-0.00073242],\n",
      "       ...,\n",
      "       [-0.00161743],\n",
      "       [ 0.00073242],\n",
      "       [-0.0015564 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00082397],\n",
      "       [ 0.00335693],\n",
      "       [-0.0015564 ],\n",
      "       ...,\n",
      "       [-0.00076294],\n",
      "       [ 0.00115967],\n",
      "       [-0.00131226]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00140381],\n",
      "       [-0.00054932],\n",
      "       [-0.00228882],\n",
      "       ...,\n",
      "       [-0.0022583 ],\n",
      "       [ 0.0005188 ],\n",
      "       [-0.00039673]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-6.4086914e-04],\n",
      "       [-1.5258789e-04],\n",
      "       [-1.9226074e-03],\n",
      "       ...,\n",
      "       [-6.1035156e-05],\n",
      "       [ 1.0375977e-03],\n",
      "       [ 1.4343262e-03]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 2.4414062e-04],\n",
      "       [ 3.0517578e-05],\n",
      "       [ 0.0000000e+00],\n",
      "       ...,\n",
      "       [ 1.2207031e-04],\n",
      "       [ 3.0517578e-05],\n",
      "       [-3.0517578e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-9.7656250e-04],\n",
      "       [ 9.1552734e-05],\n",
      "       [ 3.0517578e-05],\n",
      "       ...,\n",
      "       [-1.2512207e-03],\n",
      "       [ 7.9345703e-04],\n",
      "       [ 1.8310547e-04]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-2.5634766e-03],\n",
      "       [-4.2724609e-04],\n",
      "       [-3.0517578e-05],\n",
      "       ...,\n",
      "       [-7.9345703e-04],\n",
      "       [-1.5258789e-04],\n",
      "       [-1.5258789e-04]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00033569],\n",
      "       [ 0.00076294],\n",
      "       [ 0.00064087],\n",
      "       ...,\n",
      "       [ 0.00033569],\n",
      "       [-0.00030518],\n",
      "       [-0.00045776]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 2.4414062e-04],\n",
      "       [ 6.1035156e-05],\n",
      "       [ 3.9672852e-04],\n",
      "       ...,\n",
      "       [ 7.6293945e-04],\n",
      "       [-1.1596680e-03],\n",
      "       [-9.1552734e-04]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.00057983],\n",
      "       [0.00106812],\n",
      "       [0.0005188 ],\n",
      "       ...,\n",
      "       [0.00015259],\n",
      "       [0.00158691],\n",
      "       [0.00137329]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00088501],\n",
      "       [ 0.00082397],\n",
      "       [-0.00073242],\n",
      "       ...,\n",
      "       [-0.00134277],\n",
      "       [ 0.        ],\n",
      "       [-0.00100708]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00057983],\n",
      "       [ 0.00167847],\n",
      "       [-0.00012207],\n",
      "       ...,\n",
      "       [-0.00228882],\n",
      "       [-0.00234985],\n",
      "       [-0.00231934]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00088501],\n",
      "       [-0.0005188 ],\n",
      "       [ 0.00012207],\n",
      "       ...,\n",
      "       [-0.00158691],\n",
      "       [-0.00296021],\n",
      "       [-0.00299072]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-6.1035156e-05],\n",
      "       [-4.4555664e-03],\n",
      "       [-4.0283203e-03],\n",
      "       ...,\n",
      "       [ 2.0141602e-03],\n",
      "       [ 1.9226074e-03],\n",
      "       [ 5.1879883e-04]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[0.00112915],\n",
      "       [0.00170898],\n",
      "       [0.00350952],\n",
      "       ...,\n",
      "       [0.0020752 ],\n",
      "       [0.00308228],\n",
      "       [0.00439453]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 3.1127930e-03],\n",
      "       [ 4.1503906e-03],\n",
      "       [ 3.9367676e-03],\n",
      "       ...,\n",
      "       [-1.5869141e-03],\n",
      "       [-1.1596680e-03],\n",
      "       [-9.1552734e-05]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00112915],\n",
      "       [-0.00042725],\n",
      "       [-0.00082397],\n",
      "       ...,\n",
      "       [ 0.00100708],\n",
      "       [ 0.00030518],\n",
      "       [ 0.00341797]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00039673],\n",
      "       [-0.00024414],\n",
      "       [ 0.00048828],\n",
      "       ...,\n",
      "       [-0.00192261],\n",
      "       [-0.00231934],\n",
      "       [-0.00170898]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00033569],\n",
      "       [-0.0010376 ],\n",
      "       [-0.00259399],\n",
      "       ...,\n",
      "       [ 0.0020752 ],\n",
      "       [ 0.00326538],\n",
      "       [ 0.00201416]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00143433],\n",
      "       [ 0.00231934],\n",
      "       [ 0.00036621],\n",
      "       ...,\n",
      "       [-0.0012207 ],\n",
      "       [ 0.00292969],\n",
      "       [ 0.00286865]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 3.0517578e-05],\n",
      "       [ 8.2397461e-04],\n",
      "       [-4.5776367e-04],\n",
      "       ...,\n",
      "       [ 7.0190430e-04],\n",
      "       [ 2.8991699e-03],\n",
      "       [ 1.0986328e-03]], dtype=float32)>] samples generated from 16000_pcm_speeches\\noise\\_background_noise_\\dude_miaowing.wav\n",
      "61 slices, [<tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       ...,\n",
      "       [-0.04104614],\n",
      "       [ 0.00436401],\n",
      "       [ 0.00994873]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01409912],\n",
      "       [-0.07266235],\n",
      "       [-0.05831909],\n",
      "       ...,\n",
      "       [-0.02227783],\n",
      "       [-0.07879639],\n",
      "       [ 0.01730347]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01464844],\n",
      "       [-0.03204346],\n",
      "       [-0.03604126],\n",
      "       ...,\n",
      "       [ 0.12905884],\n",
      "       [-0.02941895],\n",
      "       [-0.04226685]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.14746094],\n",
      "       [ 0.00308228],\n",
      "       [ 0.08651733],\n",
      "       ...,\n",
      "       [ 0.12338257],\n",
      "       [-0.0105896 ],\n",
      "       [-0.06106567]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.1072998 ],\n",
      "       [-0.04388428],\n",
      "       [ 0.00823975],\n",
      "       ...,\n",
      "       [-0.00369263],\n",
      "       [-0.01171875],\n",
      "       [ 0.02319336]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.06015015],\n",
      "       [ 0.00543213],\n",
      "       [ 0.01803589],\n",
      "       ...,\n",
      "       [ 0.01675415],\n",
      "       [-0.02746582],\n",
      "       [ 0.02664185]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02670288],\n",
      "       [-0.06518555],\n",
      "       [-0.0284729 ],\n",
      "       ...,\n",
      "       [-0.07235718],\n",
      "       [-0.07049561],\n",
      "       [-0.05532837]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02377319],\n",
      "       [ 0.00164795],\n",
      "       [ 0.02719116],\n",
      "       ...,\n",
      "       [-0.00268555],\n",
      "       [ 0.0239563 ],\n",
      "       [-0.10528564]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.11087036],\n",
      "       [ 0.04003906],\n",
      "       [ 0.00234985],\n",
      "       ...,\n",
      "       [ 0.06448364],\n",
      "       [ 0.07589722],\n",
      "       [-0.07537842]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.05871582],\n",
      "       [-0.09039307],\n",
      "       [ 0.05737305],\n",
      "       ...,\n",
      "       [ 0.04544067],\n",
      "       [-0.06726074],\n",
      "       [-0.02307129]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.05065918],\n",
      "       [ 0.03964233],\n",
      "       [ 0.03213501],\n",
      "       ...,\n",
      "       [ 0.0440979 ],\n",
      "       [-0.01446533],\n",
      "       [ 0.08865356]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.14297485],\n",
      "       [-0.02069092],\n",
      "       [-0.05480957],\n",
      "       ...,\n",
      "       [-0.03469849],\n",
      "       [ 0.01849365],\n",
      "       [-0.13180542]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.12112427],\n",
      "       [-0.08132935],\n",
      "       [-0.10528564],\n",
      "       ...,\n",
      "       [ 0.05508423],\n",
      "       [ 0.00405884],\n",
      "       [ 0.01596069]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.06997681],\n",
      "       [-0.00924683],\n",
      "       [ 0.08117676],\n",
      "       ...,\n",
      "       [-0.03295898],\n",
      "       [ 0.14318848],\n",
      "       [ 0.13265991]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.0909729 ],\n",
      "       [-0.05789185],\n",
      "       [ 0.12567139],\n",
      "       ...,\n",
      "       [-0.00299072],\n",
      "       [-0.0138855 ],\n",
      "       [-0.04086304]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01333618],\n",
      "       [ 0.01522827],\n",
      "       [-0.00128174],\n",
      "       ...,\n",
      "       [-0.2262268 ],\n",
      "       [ 0.11416626],\n",
      "       [ 0.00942993]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.04315186],\n",
      "       [ 0.02609253],\n",
      "       [ 0.1272583 ],\n",
      "       ...,\n",
      "       [ 0.00067139],\n",
      "       [ 0.01083374],\n",
      "       [ 0.04898071]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00601196],\n",
      "       [ 0.00076294],\n",
      "       [ 0.03866577],\n",
      "       ...,\n",
      "       [ 0.00680542],\n",
      "       [-0.01168823],\n",
      "       [-0.03070068]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.05755615],\n",
      "       [ 0.01260376],\n",
      "       [-0.00448608],\n",
      "       ...,\n",
      "       [ 0.01528931],\n",
      "       [-0.04910278],\n",
      "       [ 0.05938721]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.10214233],\n",
      "       [-0.07168579],\n",
      "       [-0.0171814 ],\n",
      "       ...,\n",
      "       [ 0.03817749],\n",
      "       [ 0.08892822],\n",
      "       [-0.03799438]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.03820801],\n",
      "       [ 0.03253174],\n",
      "       [ 0.07952881],\n",
      "       ...,\n",
      "       [ 0.13146973],\n",
      "       [-0.00820923],\n",
      "       [-0.07946777]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.09066772],\n",
      "       [ 0.15664673],\n",
      "       [-0.06674194],\n",
      "       ...,\n",
      "       [ 0.11431885],\n",
      "       [ 0.05169678],\n",
      "       [-0.03652954]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.04110718],\n",
      "       [ 0.0993042 ],\n",
      "       [ 0.04290771],\n",
      "       ...,\n",
      "       [-0.02438354],\n",
      "       [-0.00930786],\n",
      "       [ 0.05780029]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.1461792 ],\n",
      "       [ 0.02560425],\n",
      "       [ 0.01791382],\n",
      "       ...,\n",
      "       [-0.03070068],\n",
      "       [-0.08279419],\n",
      "       [-0.00686646]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.08215332],\n",
      "       [ 0.10452271],\n",
      "       [-0.05300903],\n",
      "       ...,\n",
      "       [ 0.00622559],\n",
      "       [ 0.04748535],\n",
      "       [ 0.05383301]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02145386],\n",
      "       [-0.03338623],\n",
      "       [ 0.02767944],\n",
      "       ...,\n",
      "       [ 0.19082642],\n",
      "       [ 0.05218506],\n",
      "       [-0.01898193]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.11474609],\n",
      "       [ 0.06964111],\n",
      "       [ 0.08892822],\n",
      "       ...,\n",
      "       [-0.02688599],\n",
      "       [-0.01345825],\n",
      "       [ 0.06976318]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00775146],\n",
      "       [-0.02011108],\n",
      "       [ 0.02371216],\n",
      "       ...,\n",
      "       [-0.06436157],\n",
      "       [-0.08468628],\n",
      "       [ 0.06622314]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.13977051],\n",
      "       [-0.06341553],\n",
      "       [-0.09829712],\n",
      "       ...,\n",
      "       [ 0.05877686],\n",
      "       [-0.05099487],\n",
      "       [-0.00262451]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.06402588],\n",
      "       [-0.04000854],\n",
      "       [-0.11236572],\n",
      "       ...,\n",
      "       [ 0.03149414],\n",
      "       [-0.00918579],\n",
      "       [ 0.04418945]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.1055603 ],\n",
      "       [ 0.00585938],\n",
      "       [ 0.01898193],\n",
      "       ...,\n",
      "       [ 0.09619141],\n",
      "       [-0.03912354],\n",
      "       [-0.02780151]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00970459],\n",
      "       [ 0.08547974],\n",
      "       [-0.00415039],\n",
      "       ...,\n",
      "       [-0.06976318],\n",
      "       [ 0.0982666 ],\n",
      "       [-0.02578735]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.09240723],\n",
      "       [ 0.00390625],\n",
      "       [ 0.07006836],\n",
      "       ...,\n",
      "       [-0.03244019],\n",
      "       [-0.12487793],\n",
      "       [ 0.0718689 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.11233521],\n",
      "       [-0.09234619],\n",
      "       [-0.07107544],\n",
      "       ...,\n",
      "       [ 0.07235718],\n",
      "       [-0.09640503],\n",
      "       [-0.00308228]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02438354],\n",
      "       [-0.03268433],\n",
      "       [-0.04998779],\n",
      "       ...,\n",
      "       [ 0.00482178],\n",
      "       [-0.07312012],\n",
      "       [-0.00091553]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.04534912],\n",
      "       [-0.04837036],\n",
      "       [ 0.07409668],\n",
      "       ...,\n",
      "       [-0.3735962 ],\n",
      "       [-0.23287964],\n",
      "       [ 0.35684204]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00561523],\n",
      "       [-0.31399536],\n",
      "       [-0.04833984],\n",
      "       ...,\n",
      "       [ 0.00137329],\n",
      "       [ 0.01901245],\n",
      "       [ 0.02819824]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-3.8665771e-02],\n",
      "       [-7.4371338e-02],\n",
      "       [-6.1035156e-05],\n",
      "       ...,\n",
      "       [-9.1827393e-02],\n",
      "       [-2.5421143e-02],\n",
      "       [ 6.2927246e-02]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.00570679],\n",
      "       [-0.00509644],\n",
      "       [-0.04205322],\n",
      "       ...,\n",
      "       [ 0.12103271],\n",
      "       [ 0.00845337],\n",
      "       [-0.05426025]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.04129028],\n",
      "       [ 0.01626587],\n",
      "       [ 0.07241821],\n",
      "       ...,\n",
      "       [-0.00701904],\n",
      "       [ 0.01504517],\n",
      "       [-0.02249146]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00424194],\n",
      "       [-0.07049561],\n",
      "       [ 0.05963135],\n",
      "       ...,\n",
      "       [-0.06848145],\n",
      "       [-0.02410889],\n",
      "       [ 0.01083374]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.0553894 ],\n",
      "       [-0.00775146],\n",
      "       [-0.0668335 ],\n",
      "       ...,\n",
      "       [-0.04238892],\n",
      "       [ 0.10958862],\n",
      "       [ 0.0696106 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.04104614],\n",
      "       [ 0.05700684],\n",
      "       [-0.06491089],\n",
      "       ...,\n",
      "       [ 0.03671265],\n",
      "       [ 0.12615967],\n",
      "       [-0.04931641]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.19308472],\n",
      "       [ 0.02832031],\n",
      "       [ 0.01989746],\n",
      "       ...,\n",
      "       [ 0.03149414],\n",
      "       [ 0.05987549],\n",
      "       [-0.01324463]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.01031494],\n",
      "       [ 0.09344482],\n",
      "       [-0.04290771],\n",
      "       ...,\n",
      "       [ 0.03091431],\n",
      "       [ 0.03768921],\n",
      "       [ 0.105896  ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.04852295],\n",
      "       [ 0.00549316],\n",
      "       [ 0.11236572],\n",
      "       ...,\n",
      "       [-0.01617432],\n",
      "       [ 0.02420044],\n",
      "       [-0.00921631]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.10824585],\n",
      "       [ 0.01849365],\n",
      "       [-0.05541992],\n",
      "       ...,\n",
      "       [ 0.0065918 ],\n",
      "       [ 0.02365112],\n",
      "       [ 0.08889771]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00460815],\n",
      "       [-0.04519653],\n",
      "       [-0.01013184],\n",
      "       ...,\n",
      "       [-0.01068115],\n",
      "       [ 0.09182739],\n",
      "       [ 0.05999756]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.1242981 ],\n",
      "       [-0.03387451],\n",
      "       [ 0.0317688 ],\n",
      "       ...,\n",
      "       [-0.02557373],\n",
      "       [ 0.00558472],\n",
      "       [ 0.01119995]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.06704712],\n",
      "       [-0.03866577],\n",
      "       [ 0.07836914],\n",
      "       ...,\n",
      "       [ 0.06362915],\n",
      "       [-0.0692749 ],\n",
      "       [ 0.00082397]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.11865234],\n",
      "       [ 0.03631592],\n",
      "       [-0.00942993],\n",
      "       ...,\n",
      "       [-0.01339722],\n",
      "       [-0.14950562],\n",
      "       [-0.15646362]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.00527954],\n",
      "       [-0.0144043 ],\n",
      "       [-0.14642334],\n",
      "       ...,\n",
      "       [ 0.02502441],\n",
      "       [ 0.02914429],\n",
      "       [-0.0592041 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.01394653],\n",
      "       [ 0.04431152],\n",
      "       [ 0.02545166],\n",
      "       ...,\n",
      "       [-0.03317261],\n",
      "       [-0.06384277],\n",
      "       [-0.01461792]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.06539917],\n",
      "       [-0.00540161],\n",
      "       [ 0.01794434],\n",
      "       ...,\n",
      "       [-0.01638794],\n",
      "       [-0.10803223],\n",
      "       [-0.03842163]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.04998779],\n",
      "       [-0.02331543],\n",
      "       [-0.10525513],\n",
      "       ...,\n",
      "       [-0.0274353 ],\n",
      "       [-0.08926392],\n",
      "       [ 0.00704956]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.08175659],\n",
      "       [ 0.00933838],\n",
      "       [ 0.00332642],\n",
      "       ...,\n",
      "       [-0.08428955],\n",
      "       [ 0.01730347],\n",
      "       [ 0.05911255]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.02078247],\n",
      "       [-0.10217285],\n",
      "       [ 0.0723877 ],\n",
      "       ...,\n",
      "       [-0.03338623],\n",
      "       [-0.01333618],\n",
      "       [-0.04342651]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.02746582],\n",
      "       [ 0.03405762],\n",
      "       [-0.07247925],\n",
      "       ...,\n",
      "       [-0.04827881],\n",
      "       [ 0.06362915],\n",
      "       [ 0.00375366]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.17391968],\n",
      "       [-0.01364136],\n",
      "       [ 0.01046753],\n",
      "       ...,\n",
      "       [-0.0267334 ],\n",
      "       [-0.08328247],\n",
      "       [-0.05822754]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[ 0.03665161],\n",
      "       [ 0.01702881],\n",
      "       [-0.05337524],\n",
      "       ...,\n",
      "       [-0.1126709 ],\n",
      "       [-0.06530762],\n",
      "       [ 0.0892334 ]], dtype=float32)>, <tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n",
      "array([[-0.06396484],\n",
      "       [ 0.03543091],\n",
      "       [ 0.01025391],\n",
      "       ...,\n",
      "       [ 0.00622559],\n",
      "       [-0.07485962],\n",
      "       [ 0.10687256]], dtype=float32)>] samples generated from 16000_pcm_speeches\\noise\\_background_noise_\\running_tap.wav\n",
      "6 noise files were split into 354 noise samples where each is 1 sec. long\n"
     ]
    }
   ],
   "source": [
    "# For each noise file (files in DATASET_NOISE_PATH, ending with .wav)\n",
    "# Stack into a list - noises\n",
    "noises = []\n",
    "noise_paths = utils.get_noise_paths(DATASET_NOISE_PATH, ending=\".wav\")\n",
    "for path in noise_paths:\n",
    "    os.system(\"ffmpeg -i \" + path + \" -ar 16000 \" + path + \"temp.wav\")\n",
    "    os.remove(path)\n",
    "    os.rename(path + \"temp.wav\", path)\n",
    "    \n",
    "    sample = utils.load_noise_sample(path, SAMPLING_RATE)\n",
    "    if sample:\n",
    "        noises.extend(sample)\n",
    "noises = tf.stack(noises)\n",
    "\n",
    "print(\n",
    "    \"{} noise files were split into {} noise samples where each is {} sec. long\".format(\n",
    "        len(noise_paths), noises.shape[0], noises.shape[1] // SAMPLING_RATE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our class names: ['Benjamin_Netanyau', 'Jens_Stoltenberg', 'Julia_Gillard', 'Magaret_Tarcher', 'Nelson_Mandela']\n",
      "Processing speaker Benjamin_Netanyau\n",
      "Processing speaker Jens_Stoltenberg\n",
      "Processing speaker Julia_Gillard\n",
      "Processing speaker Magaret_Tarcher\n",
      "Processing speaker Nelson_Mandela\n",
      "Found 7501 files belonging to 5 classes.\n",
      "Using 6751 files for training.\n",
      "Using 750 files for validation.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "\n",
    "# Get the list of audio file paths along with their corresponding labels\n",
    "class_names = os.listdir(DATASET_AUDIO_PATH)\n",
    "print(\"Our class names: {}\".format(class_names,))\n",
    "\n",
    "audio_paths = []\n",
    "labels = []\n",
    "for label, name in enumerate(class_names):\n",
    "    print(\"Processing speaker {}\".format(name,))\n",
    "    dir_path = Path(DATASET_AUDIO_PATH) / name\n",
    "    speaker_sample_paths = [\n",
    "        os.path.join(dir_path, filepath)\n",
    "        for filepath in os.listdir(dir_path)\n",
    "        if filepath.endswith(\".wav\")\n",
    "    ]\n",
    "    audio_paths += speaker_sample_paths\n",
    "    labels += [label] * len(speaker_sample_paths)\n",
    "\n",
    "print(\n",
    "    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n",
    ")\n",
    "\n",
    "# Shuffle\n",
    "rng = np.random.RandomState(SHUFFLE_SEED)\n",
    "rng.shuffle(audio_paths)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "# Split into training and validation\n",
    "num_val_samples = int(VALID_SPLIT * len(audio_paths))\n",
    "print(\"Using {} files for training.\".format(len(audio_paths) - num_val_samples))\n",
    "train_audio_paths = audio_paths[:-num_val_samples]\n",
    "train_labels = labels[:-num_val_samples]\n",
    "\n",
    "print(\"Using {} files for validation.\".format(num_val_samples))\n",
    "valid_audio_paths = audio_paths[-num_val_samples:]\n",
    "valid_labels = labels[-num_val_samples:]\n",
    "\n",
    "# Create 2 datasets, one for training and the other for validation\n",
    "train_ds = utils.paths_and_labels_to_dataset(train_audio_paths, train_labels, SAMPLING_RATE)\n",
    "train_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
    "    BATCH_SIZE\n",
    ")\n",
    "\n",
    "valid_ds = utils.paths_and_labels_to_dataset(valid_audio_paths, valid_labels, SAMPLING_RATE)\n",
    "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)\n",
    "\n",
    "# Add noise to the training set\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (utils.add_noise(x, noises, scale=SCALE), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "valid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 16000, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 16000, 128)   2688        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16000, 128)   0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 16000, 128)   327808      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 16000, 128)   256         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 16000, 128)   0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16000, 128)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 8000, 128)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d (AveragePooli (None, 2666, 128)    0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 2666, 64)     65600       average_pooling1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2666, 64)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 2666, 64)     32832       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2666, 64)     8256        average_pooling1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2666, 64)     0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2666, 64)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1333, 64)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_1 (AveragePoo (None, 444, 64)      0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 444, 64)      16448       average_pooling1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 444, 64)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 444, 64)      16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 444, 64)      4160        average_pooling1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 444, 64)      0           conv1d_8[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 444, 64)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 222, 64)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_2 (AveragePoo (None, 74, 64)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 74, 32)       8224        average_pooling1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 74, 32)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 74, 32)       4128        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 74, 32)       2080        average_pooling1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 74, 32)       0           conv1d_11[0][0]                  \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 74, 32)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 37, 32)       0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_3 (AveragePoo (None, 12, 32)       0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 384)          0           average_pooling1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 384)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          98560       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 5)            645         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 621,029\n",
      "Trainable params: 621,029\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, conv_num=3, kernel_size = 3,activation=\"relu\"):\n",
    "    # Shortcut\n",
    "    s = keras.layers.Conv1D(filters, 1, padding=\"same\")(x)\n",
    "    for i in range(conv_num - 1):\n",
    "        x = keras.layers.Conv1D(filters, kernel_size, padding=\"same\")(x)\n",
    "        x = keras.layers.Activation(activation)(x)\n",
    "    x = keras.layers.Conv1D(filters, kernel_size, padding=\"same\")(x)\n",
    "    x = keras.layers.Add()([x, s])\n",
    "    x = keras.layers.Activation(activation)(x)\n",
    "    return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = keras.layers.Input(shape=input_shape, name=\"input\")\n",
    "\n",
    "    x = residual_block(inputs, 128, 2, 20)\n",
    "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "    x = residual_block(x, 64, 2, 8)\n",
    "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "    x = residual_block(x, 64, 2, 4)\n",
    "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "    x = residual_block(x, 32, 2, 4)\n",
    "\n",
    "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n",
    "\n",
    "    return keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "model = build_model((SAMPLING_RATE, 1), len(class_names))\n",
    "# model = build_model((SAMPLING_RATE // 2, 1), len(class_names))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "original_input (InputLayer)     [(None, 16000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshaped_input (Reshape)        (None, 16000, 1)     0           original_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_1 (Conv1D)         (None, 16000, 40)    120         reshaped_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_2_tanh (Conv1D)    (None, 16000, 40)    3240        dilated_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_2_sigm (Conv1D)    (None, 16000, 40)    3240        dilated_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_1 (Multiply)   (None, 16000, 40)    0           dilated_conv_2_tanh[0][0]        \n",
      "                                                                 dilated_conv_2_sigm[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "skip_1 (Conv1D)                 (None, 16000, 40)    1640        gated_activation_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_1 (Add)          (None, 16000, 40)    0           skip_1[0][0]                     \n",
      "                                                                 dilated_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_4_tanh (Conv1D)    (None, 16000, 40)    3240        residual_block_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_4_sigm (Conv1D)    (None, 16000, 40)    3240        residual_block_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_2 (Multiply)   (None, 16000, 40)    0           dilated_conv_4_tanh[0][0]        \n",
      "                                                                 dilated_conv_4_sigm[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "skip_2 (Conv1D)                 (None, 16000, 40)    1640        gated_activation_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_2 (Add)          (None, 16000, 40)    0           skip_2[0][0]                     \n",
      "                                                                 residual_block_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_8_tanh (Conv1D)    (None, 16000, 40)    3240        residual_block_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_8_sigm (Conv1D)    (None, 16000, 40)    3240        residual_block_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_3 (Multiply)   (None, 16000, 40)    0           dilated_conv_8_tanh[0][0]        \n",
      "                                                                 dilated_conv_8_sigm[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "skip_3 (Conv1D)                 (None, 16000, 40)    1640        gated_activation_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_3 (Add)          (None, 16000, 40)    0           skip_3[0][0]                     \n",
      "                                                                 residual_block_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_16_tanh (Conv1D)   (None, 16000, 40)    3240        residual_block_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_16_sigm (Conv1D)   (None, 16000, 40)    3240        residual_block_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_4 (Multiply)   (None, 16000, 40)    0           dilated_conv_16_tanh[0][0]       \n",
      "                                                                 dilated_conv_16_sigm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "skip_4 (Conv1D)                 (None, 16000, 40)    1640        gated_activation_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_4 (Add)          (None, 16000, 40)    0           skip_4[0][0]                     \n",
      "                                                                 residual_block_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_32_tanh (Conv1D)   (None, 16000, 40)    3240        residual_block_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_32_sigm (Conv1D)   (None, 16000, 40)    3240        residual_block_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_5 (Multiply)   (None, 16000, 40)    0           dilated_conv_32_tanh[0][0]       \n",
      "                                                                 dilated_conv_32_sigm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "skip_5 (Conv1D)                 (None, 16000, 40)    1640        gated_activation_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_5 (Add)          (None, 16000, 40)    0           skip_5[0][0]                     \n",
      "                                                                 residual_block_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_64_tanh (Conv1D)   (None, 16000, 40)    3240        residual_block_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_64_sigm (Conv1D)   (None, 16000, 40)    3240        residual_block_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_6 (Multiply)   (None, 16000, 40)    0           dilated_conv_64_tanh[0][0]       \n",
      "                                                                 dilated_conv_64_sigm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "skip_6 (Conv1D)                 (None, 16000, 40)    1640        gated_activation_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_6 (Add)          (None, 16000, 40)    0           skip_6[0][0]                     \n",
      "                                                                 residual_block_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_128_tanh (Conv1D)  (None, 16000, 40)    3240        residual_block_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_128_sigm (Conv1D)  (None, 16000, 40)    3240        residual_block_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_7 (Multiply)   (None, 16000, 40)    0           dilated_conv_128_tanh[0][0]      \n",
      "                                                                 dilated_conv_128_sigm[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "skip_7 (Conv1D)                 (None, 16000, 40)    1640        gated_activation_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_7 (Add)          (None, 16000, 40)    0           skip_7[0][0]                     \n",
      "                                                                 residual_block_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_256_tanh (Conv1D)  (None, 16000, 40)    3240        residual_block_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_256_sigm (Conv1D)  (None, 16000, 40)    3240        residual_block_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_8 (Multiply)   (None, 16000, 40)    0           dilated_conv_256_tanh[0][0]      \n",
      "                                                                 dilated_conv_256_sigm[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "skip_8 (Conv1D)                 (None, 16000, 40)    1640        gated_activation_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_8 (Add)          (None, 16000, 40)    0           skip_8[0][0]                     \n",
      "                                                                 residual_block_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_512_tanh (Conv1D)  (None, 16000, 40)    3240        residual_block_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_512_sigm (Conv1D)  (None, 16000, 40)    3240        residual_block_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_9 (Multiply)   (None, 16000, 40)    0           dilated_conv_512_tanh[0][0]      \n",
      "                                                                 dilated_conv_512_sigm[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "skip_9 (Conv1D)                 (None, 16000, 40)    1640        gated_activation_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "skip_connections (Add)          (None, 16000, 40)    0           skip_1[0][0]                     \n",
      "                                                                 skip_2[0][0]                     \n",
      "                                                                 skip_3[0][0]                     \n",
      "                                                                 skip_4[0][0]                     \n",
      "                                                                 skip_5[0][0]                     \n",
      "                                                                 skip_6[0][0]                     \n",
      "                                                                 skip_7[0][0]                     \n",
      "                                                                 skip_8[0][0]                     \n",
      "                                                                 skip_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16000, 40)    0           skip_connections[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_5ms (Conv1D)               (None, 16000, 40)    128040      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "downsample_to_200Hz (AveragePoo (None, 200, 40)      0           conv_5ms[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_500ms (Conv1D)             (None, 200, 40)      160040      downsample_to_200Hz[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv_500ms_target_shape (Conv1D (None, 200, 5)       20005       conv_500ms[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "downsample_to_2Hz (AveragePooli (None, 2, 5)         0           conv_500ms_target_shape[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv1D)             (None, 2, 5)         55          downsample_to_2Hz[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "final_pooling (AveragePooling1D (None, 1, 5)         0           final_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 5)            0           final_pooling[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 5)            0           reshape_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 381,340\n",
      "Trainable params: 381,340\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "844/844 [==============================] - 237s 275ms/step - loss: 1.6098 - accuracy: 0.1871 - val_loss: 1.6099 - val_accuracy: 0.1840\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60994, saving model to .\\saved_wavenet_clasifier.h5\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/844 [=====================>........] - ETA: 58s - loss: 1.6096 - accuracy: 0.2014"
     ]
    }
   ],
   "source": [
    "from WaveNetClassifier import WaveNetClassifier\n",
    "wnc = WaveNetClassifier((16000,), (5,), kernel_size = 2, dilation_depth = 9, n_filters = 40, task = 'classification')\n",
    "\n",
    "y = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "y = tf.keras.utils.to_categorical(y-1, num_classes = 5)\n",
    "\n",
    "x = np.concatenate([x for x, y in train_ds], axis=0)\n",
    "y_val = np.concatenate([y for x, y in valid_ds], axis=0)\n",
    "y_val = tf.keras.utils.to_categorical(y_val-1, num_classes = 5)\n",
    "x_val = np.concatenate([x for x, y in valid_ds], axis=0)\n",
    "# y_test = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "# x_test = np.concatenate([x for x, y in test_ds], axis=0)\n",
    "\n",
    "# print(np.shape(y))\n",
    "# print(np.shape(x))\n",
    "history = wnc.fit(x, y, validation_data = (x_val, y_val), epochs = 100, batch_size = 8, optimizer='adam', save=True, save_dir='./')\n",
    "# y_pred = wnc.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model using Adam's default learning rate\n",
    "model.compile(\n",
    "    optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Add callbacks:\n",
    "# 'EarlyStopping' to stop training when the model is not enhancing anymore\n",
    "# 'ModelCheckPoint' to always keep the model that has the best val_accuracy\n",
    "model_save_filename = \"model.h5\"\n",
    "\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    model_save_filename, monitor=\"val_accuracy\", save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING: Cropping with uneven number of extra entries on one side\n",
      "WARNING: Cropping with uneven number of extra entries on one side\n",
      "WARNING: Cropping with uneven number of extra entries on one side\n",
      "WARNING: Cropping with uneven number of extra entries on one side\n",
      "WARNING: Cropping with uneven number of extra entries on one side\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/IntPol_5/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/IntPol_5/GatherV2_2:0\", shape=(None, None, 1, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/IntPol_5/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/IntPol_5/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/IntPol_5/GatherV2_5:0\", shape=(None, None, 1, 48), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/IntPol_5/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/IntPol_4/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/IntPol_4/GatherV2_2:0\", shape=(None, None, 1, 72), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/IntPol_4/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/IntPol_4/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/IntPol_4/GatherV2_5:0\", shape=(None, None, 1, 72), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/IntPol_4/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/IntPol_3/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/IntPol_3/GatherV2_2:0\", shape=(None, None, 1, 96), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/IntPol_3/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/IntPol_3/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/IntPol_3/GatherV2_5:0\", shape=(None, None, 1, 96), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/IntPol_3/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/IntPol_2/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/IntPol_2/GatherV2_2:0\", shape=(None, None, 1, 120), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/IntPol_2/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/IntPol_2/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/IntPol_2/GatherV2_5:0\", shape=(None, None, 1, 120), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/IntPol_2/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/IntPol_1/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/IntPol_1/GatherV2_2:0\", shape=(None, None, 1, 144), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/IntPol_1/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/IntPol_1/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/IntPol_1/GatherV2_5:0\", shape=(None, None, 1, 144), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/IntPol_1/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/IntPol_0/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/IntPol_0/GatherV2_2:0\", shape=(None, None, 1, 168), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/IntPol_0/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_6/IntPol_0/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_6/IntPol_0/GatherV2_5:0\", shape=(None, None, 1, 168), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_6/IntPol_0/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Cropping with uneven number of extra entries on one side\n",
      "WARNING: Cropping with uneven number of extra entries on one side\n",
      "WARNING: Cropping with uneven number of extra entries on one side\n",
      "WARNING: Cropping with uneven number of extra entries on one side\n",
      "WARNING: Cropping with uneven number of extra entries on one side\n",
      "808/844 [===========================>..] - ETA: 4s - loss: 47.7806 - diff_out_loss: 9.5540 - diff_out_1_loss: 9.5540 - diff_out_2_loss: 9.5540 - diff_out_3_loss: 9.5540 - diff_out_4_loss: 9.5650 - diff_out_accuracy: 0.2010 - diff_out_1_accuracy: 0.2010 - diff_out_2_accuracy: 0.2010 - diff_out_3_accuracy: 0.2010 - diff_out_4_accuracy: 0.1988"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6548\\1020055542.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearlystopping_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdlcheckpoint_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \"\"\"\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    513\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \"\"\"\n\u001b[0;32m   1093\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1094\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1095\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1058\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.184"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "SAMPLES_TO_DISPLAY = 10\n",
    "\n",
    "test_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "test_ds = test_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
    "    BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=SCALE), y))\n",
    "\n",
    "y_preds_, labels_ = [], []\n",
    "for audios, labels in test_ds.take(1000):\n",
    "    y_pred = model.predict(audios)\n",
    "    \n",
    "    # Take random samples\n",
    "    audios = audios.numpy()\n",
    "    labels = labels.numpy()\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    labels_.append(labels)\n",
    "    y_preds_.append(y_pred)\n",
    "\n",
    "y_preds_ = [item for sublist in y_preds_ for item in sublist]\n",
    "labels_ = [item for sublist in labels_ for item in sublist]\n",
    "cm = ConfusionMatrixDisplay.from_predictions(labels_, y_preds_)\n",
    "accuracy_score(labels_, y_preds_)\n",
    "# cm.figure_.savefig(os.path.join(conf_mat_path, \"fold_\" + str(test_index[0]) + '_acc_' + str(accuracy_score(y_true, y_pred))) + '.png',dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6548\\2675223686.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# y_pred = model.predict(ffts)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Take random samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'audio' is not defined"
     ]
    }
   ],
   "source": [
    "SAMPLES_TO_DISPLAY = 10\n",
    "\n",
    "test_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "test_ds = test_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
    "    BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=SCALE), y))\n",
    "\n",
    "for audios, labels in test_ds.take(1):\n",
    "    # Get the signal FFT\n",
    "    # ffts = audio_to_fft(audios)\n",
    "\n",
    "    # Predict\n",
    "    # y_pred = model.predict(ffts)\n",
    "    y_pred = model.predict(audio)\n",
    "    \n",
    "    # Take random samples\n",
    "    rnd = np.random.randint(0, BATCH_SIZE, SAMPLES_TO_DISPLAY)\n",
    "    audios = audios.numpy()[rnd, :, :]\n",
    "    labels = labels.numpy()[rnd]\n",
    "    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
    "\n",
    "    for index in range(SAMPLES_TO_DISPLAY):\n",
    "        # For every sample, print the true and predicted label\n",
    "        # as well as run the voice with the noise\n",
    "        print(\n",
    "            \"Speaker: {} - Predicted: {}\".format(\n",
    "                class_names[labels[index]],\n",
    "                class_names[y_pred[index]],\n",
    "            )\n",
    "        )\n",
    "        display(Audio(audios[index, :, :].squeeze(), rate=SAMPLING_RATE))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aef9c008b311f0b7f3d27d4f3907c3c9c136ad861e53efda71f92a04d644c5c8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('usc39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
